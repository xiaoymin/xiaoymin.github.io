<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.3">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2024-08-07T09:19:09+08:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">八一菜刀</title><subtitle>八一菜刀的个人博客</subtitle><author><name>肖玉民</name></author><entry><title type="html">QWen2-72B-Instruct模型安装部署过程</title><link href="http://localhost:4000/2024/08/07/qwen2-72b-instruct-deploy/" rel="alternate" type="text/html" title="QWen2-72B-Instruct模型安装部署过程" /><published>2024-08-07T00:00:00+08:00</published><updated>2024-08-07T00:00:00+08:00</updated><id>http://localhost:4000/2024/08/07/qwen2-72b-instruct-deploy</id><content type="html" xml:base="http://localhost:4000/2024/08/07/qwen2-72b-instruct-deploy/">&lt;h2 id=&quot;一基础信息&quot;&gt;一、基础信息&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;操作系统&lt;/strong&gt;：&lt;strong&gt;Ubuntu 22.04.3 LTS&lt;/strong&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;GPU:&lt;/strong&gt; &lt;strong&gt;A800(80GB) * 8&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;内存&lt;/strong&gt;：1TB&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/rag/torchv/qwen2-72b/image-20240806104952860.png&quot; alt=&quot;image-20240806104952860&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/rag/torchv/qwen2-72b/image-20240806110115152.png&quot; alt=&quot;image-20240806110115152&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;二软件信息&quot;&gt;二、软件信息&lt;/h2&gt;

&lt;p&gt;Python: 3.10&lt;/p&gt;

&lt;p&gt;Pytorch：2.3.0&lt;/p&gt;

&lt;p&gt;Transformers：4.43.0&lt;/p&gt;

&lt;p&gt;vLLM：0.5.0&lt;/p&gt;

&lt;p&gt;cuda： 12.2&lt;/p&gt;

&lt;p&gt;模型: &lt;a href=&quot;https://huggingface.co/Qwen/Qwen2-72B-Instruct&quot;&gt;QWen2-72B-Instruct&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;三安装步骤&quot;&gt;三、安装步骤&lt;/h2&gt;

&lt;h3 id=&quot;1安装conda&quot;&gt;1、安装Conda&lt;/h3&gt;

&lt;p&gt;Conda 是一个开源的包管理系统和环境管理系统，旨在简化软件包的安装、配置和使用&lt;/p&gt;

&lt;p&gt;对于Python环境的部署，能够非常方便的切换环境。&lt;/p&gt;

&lt;p&gt;可以通过conda官网链接下载安装：&lt;a href=&quot;https://www.anaconda.com/download#downloads&quot;&gt;https://www.anaconda.com/download#downloads&lt;/a&gt;&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# 下载&lt;/span&gt;
wget https://repo.anaconda.com/archive/Anaconda3-2023.09-0-Linux-x86_64.sh
&lt;span class=&quot;c&quot;&gt;# 安装&lt;/span&gt;
bash Anaconda3-2023.09-0-Linux-x86_64.sh
&lt;span class=&quot;c&quot;&gt;# 配置环境变量&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'export PATH=&quot;/path/to/anaconda3/bin:$PATH&quot;'&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; ~/.bashrc
&lt;span class=&quot;nb&quot;&gt;source&lt;/span&gt; ~/.bashrc
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;安装完成后，通过命令验证安装是否成功&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;conda &lt;span class=&quot;nt&quot;&gt;--version&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;安装完成之后，可以配置镜像源，方便快速下载依赖包&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# 配置源&lt;/span&gt;

conda config &lt;span class=&quot;nt&quot;&gt;--add&lt;/span&gt; channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/
conda config &lt;span class=&quot;nt&quot;&gt;--add&lt;/span&gt; channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/
conda config &lt;span class=&quot;nt&quot;&gt;--set&lt;/span&gt; show_channel_urls &lt;span class=&quot;nb&quot;&gt;yes


&lt;/span&gt;conda config &lt;span class=&quot;nt&quot;&gt;--add&lt;/span&gt; channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge/
conda config &lt;span class=&quot;nt&quot;&gt;--add&lt;/span&gt; channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/msys2/
conda config &lt;span class=&quot;nt&quot;&gt;--add&lt;/span&gt; channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/bioconda/
conda config &lt;span class=&quot;nt&quot;&gt;--add&lt;/span&gt; channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/menpo/
conda config &lt;span class=&quot;nt&quot;&gt;--add&lt;/span&gt; channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;conda的相关命令&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &lt;span class=&quot;c&quot;&gt;# 指定虚拟环境名称为llm，python版本是3.9&lt;/span&gt;
 conda create &lt;span class=&quot;nt&quot;&gt;--name&lt;/span&gt; llm &lt;span class=&quot;nv&quot;&gt;python&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;3.9
 &lt;span class=&quot;c&quot;&gt;# 激活conda新环境&lt;/span&gt;
 conda activate llm
 &lt;span class=&quot;c&quot;&gt;# 查看当前环境列表&lt;/span&gt;
 conda &lt;span class=&quot;nb&quot;&gt;env &lt;/span&gt;list
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;2下载qwen2-72b-instruct模型&quot;&gt;2、下载QWen2-72B-Instruct模型&lt;/h3&gt;

&lt;p&gt;Huggingface：&lt;a href=&quot;https://huggingface.co/Qwen/Qwen2-72B-Instruct&quot;&gt;https://huggingface.co/Qwen/Qwen2-72B-Instruct&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;ModelScope：&lt;a href=&quot;https://modelscope.cn/models/qwen/Qwen2-72B-Instruct&quot;&gt;https://modelscope.cn/models/qwen/Qwen2-72B-Instruct&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;两个地址都可以下载，下载完成后，将模型文件存放在服务器上。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;⚠️ 注意服务器的磁盘空间。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;3安装pytorch等环境依赖信息&quot;&gt;3、安装Pytorch等环境依赖信息&lt;/h3&gt;

&lt;blockquote&gt;
  &lt;p&gt;⚠️ 在安装Pytorch时，需要保证和cuda驱动版本保持一致，不然会出现各种莫名其妙的问题&lt;/p&gt;

  &lt;p&gt;版本选择参考：&lt;a href=&quot;https://pytorch.org/get-started/locally/&quot;&gt;https://pytorch.org/get-started/locally/&lt;/a&gt;&lt;/p&gt;

  &lt;p&gt;通过conda创建一个新的环境，然后切换后安装依赖包&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/rag/torchv/qwen2-72b/image-20240806135441512.png&quot; alt=&quot;image-20240806135441512&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;4-安装vllm&quot;&gt;4、 安装vLLM&lt;/h3&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;vLLM&lt;/code&gt; 框架是一个高效的大语言模型&lt;strong&gt;推理和部署服务系统&lt;/strong&gt;，具备以下特性：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;高效的内存管理&lt;/strong&gt;：通过 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;PagedAttention&lt;/code&gt; 算法，&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;vLLM&lt;/code&gt; 实现了对 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;KV&lt;/code&gt; 缓存的高效管理，减少了内存浪费，优化了模型的运行效率。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;高吞吐量&lt;/strong&gt;：&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;vLLM&lt;/code&gt; 支持异步处理和连续批处理请求，显著提高了模型推理的吞吐量，加速了文本生成和处理速度。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;易用性&lt;/strong&gt;：&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;vLLM&lt;/code&gt; 与 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;HuggingFace&lt;/code&gt; 模型无缝集成，支持多种流行的大型语言模型，简化了模型部署和推理的过程。兼容 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;OpenAI&lt;/code&gt; 的 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;API&lt;/code&gt; 服务器。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;分布式推理&lt;/strong&gt;：框架支持在多 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GPU&lt;/code&gt; 环境中进行分布式推理，通过模型并行策略和高效的数据通信，提升了处理大型模型的能力。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;开源共享&lt;/strong&gt;：&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;vLLM&lt;/code&gt; 由于其开源的属性，拥有活跃的社区支持，这也便于开发者贡献和改进，共同推动技术发展。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;GitHub：&lt;a href=&quot;https://github.com/vllm-project/vllm&quot;&gt;https://github.com/vllm-project/vllm&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;文档：&lt;a href=&quot;https://docs.vllm.ai/en/latest/&quot;&gt;https://docs.vllm.ai/en/latest/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;在通过&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;conda&lt;/code&gt;创建了初始环境后，可以直接通过&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pip&lt;/code&gt;进行安装&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;pip &lt;span class=&quot;nb&quot;&gt;install &lt;/span&gt;vllm
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;更多的安装方式，可以参考官网文档：&lt;a href=&quot;https://docs.vllm.ai/en/stable/getting_started/installation.html&quot;&gt;https://docs.vllm.ai/en/stable/getting_started/installation.html&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;5模型验证&quot;&gt;5、模型验证&lt;/h3&gt;

&lt;p&gt;可以通过一个python脚本来验证当前的模型是否可用&lt;/p&gt;

&lt;p&gt;脚本如下：&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# test.py
&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;vllm&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;LLM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SamplingParams&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;transformers&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;AutoTokenizer&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;os&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;json&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;get_completion&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;prompts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max_tokens&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;512&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;temperature&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;top_p&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.95&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max_model_len&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2048&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;stop_token_ids&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# 创建采样参数。temperature 控制生成文本的多样性，top_p 控制核心采样的概率
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;sampling_params&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SamplingParams&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;temperature&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;temperature&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;top_p&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;top_p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max_tokens&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_tokens&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stop_token_ids&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stop_token_ids&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# 初始化 vLLM 推理引擎
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;llm&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;LLM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max_model_len&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_model_len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;trust_remote_code&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;llm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;generate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;prompts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sampling_params&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;


&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;__name__&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;__main__&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;    
    &lt;span class=&quot;c1&quot;&gt;# 初始化 vLLM 推理引擎
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'/mnt/soft/models/qwen/Qwen2-72B-Instruct'&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# 指定模型路径
&lt;/span&gt;    &lt;span class=&quot;c1&quot;&gt;# model=&quot;qwen/Qwen2-7B-Instruct&quot; # 指定模型名称，自动下载模型
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# 加载分词器后传入vLLM 模型，但不是必要的。
&lt;/span&gt;    &lt;span class=&quot;c1&quot;&gt;# tokenizer = AutoTokenizer.from_pretrained(model, use_fast=False) 
&lt;/span&gt;    
    &lt;span class=&quot;n&quot;&gt;text&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;你好，帮我介绍一下什么时大语言模型。&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;s&quot;&gt;&quot;可以给我将一个有趣的童话故事吗？&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;get_completion&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max_tokens&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;512&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;temperature&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;top_p&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max_model_len&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2048&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# 输出是一个包含 prompt、生成文本和其他信息的 RequestOutput 对象列表。
&lt;/span&gt;    &lt;span class=&quot;c1&quot;&gt;# 打印输出。
&lt;/span&gt;    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;prompt&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;prompt&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;generated_text&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Prompt: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;prompt&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;, Generated text: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;generated_text&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;在终端执行python脚本，可以看到控制台是否正常输出&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;python test.py
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;6启动服务--包装openai格式的接口&quot;&gt;6、启动服务 &amp;amp; 包装OpenAI格式的接口&lt;/h3&gt;

&lt;p&gt;验证模型可用后，那么就可以通过vLLM提供的模块，将整个模型服务包装成OpenAI格式的HTTP服务，提供给上层应用使用。&lt;/p&gt;

&lt;p&gt;需要注意的参数配置：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;--model&lt;/code&gt; 参数指定模型名称&amp;amp;路径。&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;--served-model-name&lt;/code&gt; 指定服务模型的名称。&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;--max-model-len&lt;/code&gt; 指定模型的最大长度，如果不指定，那么会从模型配置文件中自动加载，QWen2-72B模型支持最大128K&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;--tensor-parallel-size&lt;/code&gt;  指定多个GPU服务运行,QWen2-72B的模型，单卡GPU无法支撑。&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;--gpu-memory-utilization&lt;/code&gt;  用于模型执行器的GPU内存分数，范围从0到1。例如，值为0.5意味着GPU内存利用率为50%。如果未指定，将使用&lt;strong&gt;默认值0.9&lt;/strong&gt;。&lt;strong&gt;vllm通过此参数预分配了部分显存，避免模型在调用的时候频繁的申请显存&lt;/strong&gt;。&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;关于vllm的更多参数，可以参考官方文档：&lt;a href=&quot;https://docs.vllm.ai/en/stable/models/engine_args.html&quot;&gt;https://docs.vllm.ai/en/stable/models/engine_args.html&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;这里可以使用&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;tmux&lt;/code&gt;命令来进行服务的运行。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;tmux&lt;/code&gt;（Terminal Multiplexer）是一个强大的终端复用器，可以让用户在一个终端窗口中同时使用多个会话。使用 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;tmux&lt;/code&gt; 可以提高工作效率，便于管理长期运行的任务和多任务操作&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;python3 &lt;span class=&quot;nt&quot;&gt;-m&lt;/span&gt; vllm.entrypoints.openai.api_server &lt;span class=&quot;nt&quot;&gt;--model&lt;/span&gt; /mnt/torchv/models/Qwen2-72B-Instruct  &lt;span class=&quot;nt&quot;&gt;--served-model-name&lt;/span&gt; QWen2-72B-Instruct &lt;span class=&quot;nt&quot;&gt;--tensor-parallel-size&lt;/span&gt; 8 &lt;span class=&quot;nt&quot;&gt;--gpu-memory-utilization&lt;/span&gt; 0.7
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/rag/torchv/qwen2-72b/image-20240806111100747.png&quot; alt=&quot;image-20240806111100747&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;出现端口等信息则代表当前的模型服务启动成功！！！&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;首先创建一个新会话&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;tmux new &lt;span class=&quot;nt&quot;&gt;-t&lt;/span&gt; llm
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;进入会话&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;tmux attach &lt;span class=&quot;nt&quot;&gt;-t&lt;/span&gt; llm
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;启动命令：&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;python &lt;span class=&quot;nt&quot;&gt;-m&lt;/span&gt; xxx
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;退出当前会话&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;如果没反应就多试几次&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;英文输入下 ctrl + b  然后输入d
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;通过curl命令验证大模型OpenAI接口服务是否可用，脚本如下：&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;curl http://localhost:8000/v1/chat/completions &lt;span class=&quot;nt&quot;&gt;-H&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Content-Type: application/json&quot;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-d&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'{
  &quot;model&quot;: &quot;QWen2-72B-Instruct&quot;,
  &quot;messages&quot;: [
      {
          &quot;role&quot;: &quot;user&quot;,
          &quot;content&quot;: &quot;给我讲一个童话故事&quot;
      }
  ],
  &quot;stream&quot;: true,
  &quot;temperature&quot;: 0.9,
  &quot;top_p&quot;: 0.7,
  &quot;top_k&quot;: 20,
  &quot;max_tokens&quot;: 512
}'&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;四总结&quot;&gt;四、总结&lt;/h2&gt;

&lt;p&gt;目前的开源生态已经非常成熟了，vLLM这样的工具能够轻松实现对大模型的快速部署，工作效率上大大提升&lt;/p&gt;

&lt;h2 id=&quot;五references&quot;&gt;五、References&lt;/h2&gt;

&lt;h3 id=&quot;官网资源等信息&quot;&gt;官网资源等信息&lt;/h3&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;资源&lt;/th&gt;
      &lt;th&gt;地址&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;QWen&lt;/td&gt;
      &lt;td&gt;GitHub：&lt;a href=&quot;https://github.com/QwenLM/Qwen&quot;&gt;https://github.com/QwenLM/Qwen&lt;/a&gt;&lt;br /&gt;Huggingface：&lt;a href=&quot;https://huggingface.co/Qwen&quot;&gt;https://huggingface.co/Qwen&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;ModelScope：&lt;a href=&quot;https://modelscope.cn/organization/qwen?tab=model&quot;&gt;https://modelscope.cn/organization/qwen?tab=model&lt;/a&gt;&lt;br /&gt;docs:&lt;a href=&quot;https://qwen.readthedocs.io/zh-cn/latest/getting_started/quickstart.html#&quot;&gt;https://qwen.readthedocs.io/zh-cn/latest/getting_started/quickstart.html#&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Pytorch&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://pytorch.org/get-started/locally/&quot;&gt;https://pytorch.org/get-started/locally/&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Conda&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://www.anaconda.com&quot;&gt;https://www.anaconda.com&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;vLLM&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://docs.vllm.ai/en/latest/getting_started/installation.html&quot;&gt;https://docs.vllm.ai/en/latest/getting_started/installation.html&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&quot;权重文件下载不完全&quot;&gt;权重文件下载不完全&lt;/h3&gt;

&lt;p&gt;在本次部署过程中，碰到了下载模型权重文件不完整的情况，导致通过&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;vLLM&lt;/code&gt;部署不起来，可以通过Linux的命令&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sha256sum&lt;/code&gt;工具来对模型权重文件进行检查，对比网站上的模型权重文件的sha256是否一致，如果不一致，需要重新下载安装&lt;/p&gt;

&lt;p&gt;命令如下：&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;sha256sum &lt;/span&gt;your_local_file
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/rag/torchv/qwen2-72b/image-20240806095033934.png&quot; alt=&quot;image-20240806095033934&quot; /&gt;&lt;/p&gt;</content><author><name>八一菜刀</name></author><category term="大模型" /><category term="RAG实践" /><category term="TorchV" /><category term="RAG概述" /><category term="RAG" /><category term="大模型" /><category term="LLM" /><summary type="html">一、基础信息</summary></entry><entry><title type="html">RAG工程实践拦路虎之一：PDF格式解析杂谈</title><link href="http://localhost:4000/2024/07/08/torchv-pdf-01/" rel="alternate" type="text/html" title="RAG工程实践拦路虎之一：PDF格式解析杂谈" /><published>2024-07-08T00:00:00+08:00</published><updated>2024-07-08T00:00:00+08:00</updated><id>http://localhost:4000/2024/07/08/torchv-pdf-01</id><content type="html" xml:base="http://localhost:4000/2024/07/08/torchv-pdf-01/">&lt;h2 id=&quot;背景&quot;&gt;背景&lt;/h2&gt;

&lt;p&gt;PDF（Portable Document Format）是一种广泛用于文档交换的文件格式，由Adobe Systems开发。它具有跨平台性、固定布局和易于打印等特点，因此在商业、学术和个人领域广泛应用。然而，PDF文件的解析一直是一个具有挑战性的问题，因为其内部结构的复杂性和多样性，使得提取其中的文本、图片和表格等内容并不是一件容易的事情。&lt;/p&gt;

&lt;h2 id=&quot;技术方案&quot;&gt;技术方案&lt;/h2&gt;

&lt;p&gt;在目前的PDF文件解析领域中，我们可以将其大致分为以下几类技术方案：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;LLM/视觉大模型解析&lt;/strong&gt;：LLM（Large Language Model）大型语言模型在近年来的发展中，展现出了强大的语言理解和生成能力。通过训练大规模的神经网络，可以实现对PDF文件中文字内容的理解和提取，这种方法尤其适用于那些布局复杂、内容丰富的PDF文件。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;OCR模型&lt;/strong&gt;：光学字符识别（OCR）模型专门设计用于将PDF文件中的图像转换为可编辑的文本。这种技术在处理扫描版或图像化的PDF文档时尤其有用。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;传统规则提取&lt;/strong&gt;：传统的PDF解析方式可能包括基于规则的文本提取、图像处理和表格识别等方法。虽然这些方法可能不如深度学习模型那样灵活，但在某些情况下仍然是有效的选择。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;各个解决方案目前可能需要配合使用，因为PDF格式本身的复杂程度，一项技术方案可能是&lt;strong&gt;无法100%满足业务需求&lt;/strong&gt;的，这里面需要考虑的是：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;文档提取还原度&lt;/strong&gt;：通过技术手段，能够完整的提取PDF中的各项元素，包括文本、表格、图片、链接、图形、目录等等信息&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;高效/💰成本&lt;/strong&gt;：在RAG知识库问答的产品中，考虑到文本还需要Embedding的过程，因此在提取过程中如何更高效，成本更低也是需要着重考虑到事项。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;稳定/幂等&lt;/strong&gt;：我们知道大模型可能是出现幻觉的，如果用大模型来提取PDF中的内容，是否能足够保证稳定性。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;当我们处理解析PDF时，我们需要可以讲每一项的难点都进行拆分，从需求出发，逐一进行攻破，找到解决方案。&lt;/p&gt;

&lt;p&gt;其实我觉得技术人员如果能&lt;strong&gt;通过技术手段确定PDF中的Block(块)以及阅读顺序，按Block(块)进行输出转换(Markdown/Html等)，这里面包括的Block块元素：文本、图片、表格等等。那么这个提取的效果就会达到我们的最优&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;而这个目标是我们接下来要重点讨论的。&lt;/p&gt;

&lt;h2 id=&quot;技术难点&quot;&gt;技术难点&lt;/h2&gt;

&lt;p&gt;在考虑解析PDF文件时，我们需要根据当前的技术栈发展情况，并结合实际的业务诉求，综合考量这其中的技术难点，因为每一项技术难点所涉及的技术方案都会需要一个算法/或者技术手段去突破。&lt;/p&gt;

&lt;p&gt;而开发者从解析的效果去考虑，可以从简单的做起，逐步突破难点，这对于开发人员自身的自信心提升也是一种正向的导向。在整个PDF解析过程中，我觉得以下几项是比较难处理的：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;布局解析困难&lt;/strong&gt;：PDF文件的布局可能会因为不同的作者、工具或用途而有所不同，因此解析其布局是一个具有挑战性的任务。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;格式错综复杂&lt;/strong&gt;：PDF文件中可能包含各种格式的内容，包括&lt;strong&gt;文字&lt;/strong&gt;、&lt;strong&gt;图像&lt;/strong&gt;、&lt;strong&gt;表格&lt;/strong&gt;等，因此解析其内容需要考虑到这种多样性和复杂性。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;复合表格&lt;/strong&gt;：纵向/横向合并的复杂表格，在PDF中进行抽象还原是最难处理的问题之一&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;文本、图片、表格顺序提取&lt;/strong&gt;：提取PDF文件中的文本、图片和表格，并确保它们的顺序正确性，是一个需要解决的重要问题。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;文档结构还原&lt;/strong&gt;：还原PDF文件的文档结构，包括标题、目录等信息，是实现自动化文档处理和理解的关键步骤之一。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;元素重叠&lt;/strong&gt;：从PDF100%效果还原的角度考虑，图片/文本之间的重叠，图片合并，合并后不失真等，也是需要考虑的事项之一&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;元数据提取&lt;/strong&gt;：在PDF中隐藏的元数据信息是RAG产品的关键数据，比如链接、目录、字体等等&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;扫描件&lt;/strong&gt;：PDF中如果是扫描件，依靠OCR模型可能是无法有效的提取，这里面包含了清晰度、模型的稳定性等等问题&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Latex公式提取&lt;/strong&gt;：在一些特殊领域，PDF文本中包含了Latex等数学公式。通过完整的提取和转换是对RAG问答的有效补充&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;技术可行性&quot;&gt;技术可行性&lt;/h2&gt;

&lt;p&gt;我们从解析PDF的技术可行性角度，考虑哪些方面值得我们重点关注和突破：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;文字提取能力，逐行提取&lt;/strong&gt;：确保能够准确地提取PDF文件中的文字内容，并按照正确的顺序进行排列和输出，避免文字乱码(字体)。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;简单/复杂表格完整提取&lt;/strong&gt;：对PDF文件中的表格进行完整提取，包括表格内的内容和格式。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;图片提取/合并&lt;/strong&gt;：提取PDF文件中的图片，并保留其原始质量和格式。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;文档布局(Block块的标识)识别&lt;/strong&gt;：识别PDF文件的布局，包括页面的排列方式、文本和图片的位置等信息。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;文档结构识别(标题、目录)，内容顺序输出&lt;/strong&gt;：识别PDF文件的结构，包括标题、目录等信息，并确保输出内容的顺序正确。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;转换为Markdown格式&lt;/strong&gt;：将解析后的PDF文件内容转换为Markdown格式，以便于后续的处理和分享。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;开源技术方案&quot;&gt;开源技术方案&lt;/h2&gt;

&lt;p&gt;结合上面的技术难点/方案及可行性上去分析，我们可以看看目前开源的技术组件中，有哪些是我们可以考虑进行结合的。&lt;/p&gt;

&lt;p&gt;因为目前TorchV系统主要以Java+Python双语作为底层的应用开发语言，接下来我们可以看看在这两个编程语言中，有哪些开源的方案可以使用。&lt;/p&gt;

&lt;h3 id=&quot;java生态&quot;&gt;Java生态&lt;/h3&gt;

&lt;p&gt;在Java生态中，对于PDF组件处理的开源方案不多见，Apache PDFBOX是当前最强的，也是最好的&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;名称&lt;/th&gt;
      &lt;th&gt;地址&lt;/th&gt;
      &lt;th&gt;说明&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Apache PDFBox&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://github.com/apache/pdfbox&quot;&gt;https://github.com/apache/pdfbox&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;提供开箱即用的文本、图片内容提取方式，并且可以基于Stream接口重写各项元素的解析实现，&lt;strong&gt;并能输出元素的坐标信息&lt;/strong&gt;。开发者可以根据元素的坐标信息结合算法进行内容的高度还原。唯一的缺点是没有表格组件提取的API供开发人员使用。&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;tabula-java&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://github.com/tabulapdf/tabula-java&quot;&gt;https://github.com/tabulapdf/tabula-java&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;基于Apache PDFBOx组件的表格提取实现&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&quot;python生态&quot;&gt;Python生态&lt;/h3&gt;

&lt;p&gt;Python生态的PDF提取组件还是蛮多的，不过也是有不同的侧重，比如pdfplumber、camelot等都专注在表格的提取上，提供了开箱即用的方案。&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;名称&lt;/th&gt;
      &lt;th&gt;地址&lt;/th&gt;
      &lt;th&gt;说明&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;pypdf&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://github.com/py-pdf/pypdf&quot;&gt;https://github.com/py-pdf/pypdf&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;一个纯Python PDF库，能够分割、合并、裁剪和转换PDF文件的页面&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;PyMuPDF(AGPL)&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://github.com/pymupdf/PyMuPDF&quot;&gt;https://github.com/pymupdf/PyMuPDF&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;高性能 Python 库，用于 PDF（和其他）文档的数据提取、分析、转换和操作。&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/jsvine/pdfplumber&quot;&gt;pdfplumber&lt;/a&gt;&lt;/strong&gt;(MIT)&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://github.com/jsvine/pdfplumber&quot;&gt;https://github.com/jsvine/pdfplumber&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;查看 PDF 以获取有关每个字符、矩形、线条等的详细信息，并轻松提取文本和表格。&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/camelot-dev/camelot&quot;&gt;camelot&lt;/a&gt;&lt;/strong&gt;（MIT）&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://github.com/camelot-dev/camelot&quot;&gt;https://github.com/camelot-dev/camelot&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;专注于PDF中表格的提取，包括复杂的表格&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&quot;ocr生态大模型&quot;&gt;OCR生态/大模型&lt;/h3&gt;

&lt;p&gt;在上面Python和Java生态库的开源组件，基本都是针对文字的PDF处理为主，当我们的PDF是扫描件时，那上面的组件统统失效，都提取不出来文本信息。&lt;/p&gt;

&lt;p&gt;此时就需要用到OCR的模型进行提取。&lt;/p&gt;

&lt;p&gt;考虑到如果是OCR提取，那么最终的目的是将PDF文件Page页码内容提取出完成的图片Image，所以本质上是对图片内容的理解&lt;/p&gt;

&lt;p&gt;可以考虑的开源组件如下：&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;名称&lt;/th&gt;
      &lt;th&gt;地址&lt;/th&gt;
      &lt;th&gt;说明&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;marker(GPL)&lt;/td&gt;
      &lt;td&gt;https://github.com/VikParuchuri/marker&lt;/td&gt;
      &lt;td&gt;基于模型将PDF文件内容提取为Markdown格式&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;surya(GPL)&lt;/td&gt;
      &lt;td&gt;https://github.com/VikParuchuri/surya&lt;/td&gt;
      &lt;td&gt;OCR、布局分析、阅读顺序、线条检测（支持90 多种语言）&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;tesseract(Apache 2)&lt;/td&gt;
      &lt;td&gt;https://github.com/tesseract-ocr/tesseract&lt;/td&gt;
      &lt;td&gt;老牌OCR组件，支持100多种语言&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;RapidOCR(Apache)&lt;/td&gt;
      &lt;td&gt;https://github.com/RapidAI/RapidOCR&lt;/td&gt;
      &lt;td&gt;基于 ONNXRuntime、OpenVION 和 PaddlePaddle 的出色 OCR 多种编程语言工具包。&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;PaddleOCR(Apache)&lt;/td&gt;
      &lt;td&gt;https://github.com/PaddlePaddle/PaddleOCR&lt;/td&gt;
      &lt;td&gt;基于飞桨的出色多语言OCR工具包（实用的超轻量级OCR系统，支持80+语言识别）&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;EasyOCR(Apache )&lt;/td&gt;
      &lt;td&gt;https://github.com/JaidedAI/EasyOCR&lt;/td&gt;
      &lt;td&gt;Python\C++开发，支持80多种语言OCR识别&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;技术准备细节&quot;&gt;技术准备/细节&lt;/h2&gt;

&lt;p&gt;在解析PDF时，我们也会有一些其他方面的知识储备，以便我们快速应对不同的业务需求及应用产品形态。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;1、图形类API&lt;/strong&gt;：不管是Java还是Python里面，对于处理PDF中间件的部分，都需要对图形类的API/算法熟悉和掌握，这里面包含图形的转换、缩放、矩阵坐标、截取等等，都会在PDF提取的过程中使用到。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;2、PDF标准&lt;/strong&gt;：在处理PDF中，结合开源的技术中间件，对于PDF的ISO标准，我们也是需要了解的，这样更加有利于开发人员理解中间件的代码写法及含义。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;3、边/线/矩阵算法等&lt;/strong&gt;：对于文本/边框的聚类算法等，在根据元素坐标高效还原时，利用高效的算法可以提高解析速度以及内容还原度&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;4、OCR/LLM模型等&lt;/strong&gt;：了解学习在用OCR/LLM模型分析布局、边界检测等等技术上的一些算法及数据工程上的实践&lt;/p&gt;

&lt;p&gt;5、&lt;strong&gt;PDF页面旋转&lt;/strong&gt;：有时候原PDF可能会有旋转(0、90、180、270度)，需先校正后，再次提取内容&lt;/p&gt;

&lt;p&gt;6、&lt;strong&gt;字体/乱码&lt;/strong&gt;：系统/服务器中缺失PDF中的字体，导致文本提取乱码&lt;/p&gt;

&lt;h2 id=&quot;最后&quot;&gt;最后&lt;/h2&gt;

&lt;p&gt;本文从大的方面简单概括了在PDF解析处理过程中的技术方案/难点/开源技术方案等内容，后面我会从一些细节方面来逐一分享我们在构建TorchV产品时，解析PDF文件过程中的一些问题及技术实践,包括对表格的提取，感兴趣的可以关注我们😁。&lt;/p&gt;

&lt;p&gt;另外，我们团队提供了一个PDF解析的Demo地址，针对文本类的PDF(暂时不支持扫描件)，可以进行试用体验。&lt;/p&gt;

&lt;p&gt;地址：&lt;a href=&quot;http://tabletest.torchv.com:8010/&quot;&gt;http://tabletest.torchv.com:8010/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/rag/torchv/pdf-01/image-20240706170720200.png&quot; alt=&quot;image-20240706170720200&quot; /&gt;&lt;/p&gt;</content><author><name>八一菜刀</name></author><category term="大模型" /><category term="RAG实践" /><category term="TorchV" /><category term="RAG概述" /><category term="RAG" /><category term="大模型" /><category term="LLM" /><summary type="html">背景</summary></entry><entry><title type="html">我对《RAG/大模型/非结构化数据知识库类产品》技术架构的思考、杂谈</title><link href="http://localhost:4000/2024/07/03/torchv-think/" rel="alternate" type="text/html" title="我对《RAG/大模型/非结构化数据知识库类产品》技术架构的思考、杂谈" /><published>2024-07-03T00:00:00+08:00</published><updated>2024-07-03T00:00:00+08:00</updated><id>http://localhost:4000/2024/07/03/torchv-think</id><content type="html" xml:base="http://localhost:4000/2024/07/03/torchv-think/">&lt;h2 id=&quot;1前言&quot;&gt;1、前言&lt;/h2&gt;

&lt;p&gt;在6.28/29的稀土掘金开发者大会RAG专场上，我们公司CEO员外代表TorchV分享了我们在《RAG在企业应用中落地的难点与创新》&lt;/p&gt;

&lt;p&gt;其中最后分享了两个观点：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;AI在应用场景落地时有三个特点：功能小、质量高、价值大&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&quot;/assets/images/rag/torchv/rag-4/image-20240701143924758.png&quot; alt=&quot;image-20240701143924758&quot; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;如果说做产品是把一横做好的话，那么去做企业落地服务就是一竖，从需求和方案，再到 POC，和最后交付。&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&quot;/assets/images/rag/torchv/rag-4/image-20240701143941791.png&quot; alt=&quot;image-20240701143941791&quot; /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;对于AI应用的三个特点，我们在落地的时候，其实碰到的问题蛮多的，但是用过大模型或者AI产品的人应该都知道，目前基于大模型应用开发的C端产品其实在整体给人的感觉都是相对较小的工具居多，在帮助人类提效这件事上，借助于AI工具，能很好的完成日常繁杂的工作和学习任务。比如&lt;strong&gt;AI翻译&lt;/strong&gt;、&lt;strong&gt;网页总结&lt;/strong&gt;插件等等。这类产品更多的是偏C端为主，借助于互联网的生态以及开源技术的发展，只要功能/交互满足用户的要求，很快就能打动C端用户进行尝鲜试用甚至付费。&lt;/p&gt;

&lt;p&gt;但是做B端类的产品，整个交付的过程就明显和C端不一样，在B端我们除了产品本身需要功能足够强大之外，我们还需要做AI的落地交付，这里面包含&lt;strong&gt;私有化定制&lt;/strong&gt;/&lt;strong&gt;客户培训&lt;/strong&gt;/&lt;strong&gt;私有化部署&lt;/strong&gt;/&lt;strong&gt;软硬件适配&lt;/strong&gt;等等繁杂的工作，整个交付周期漫长的多。这明显是和上面第二个观点相呼应的，&lt;strong&gt;产品+服务&lt;/strong&gt;才能综合服务好B端的客户。&lt;/p&gt;

&lt;p&gt;本篇是结合我们公司在B端RAG/大模型应用产品的落地交付的场景考虑，以实际场景出发，谈谈我对知识库类产品的技术架构的思考总结。&lt;/p&gt;

&lt;h2 id=&quot;2业务功能技术组件拆解抽象&quot;&gt;2、业务功能/技术组件拆解抽象&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/rag/torchv/rag-4/image-20240703085452132.png&quot; alt=&quot;image-20240703085452132&quot; /&gt;&lt;/p&gt;

&lt;p&gt;在文章的标题中，我已经标注了范围: &lt;strong&gt;RAG&lt;/strong&gt;、&lt;strong&gt;大模型&lt;/strong&gt;、&lt;strong&gt;非结构化数据&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;我们从这三个方面出发，在软件层面，我们如何来考虑这些新型的技术名词，将他们从技术/产品功能的角度进行拆解，实现对应的功能交付给我们的客户。&lt;/p&gt;

&lt;p&gt;从业务的功能诉求来看，主要有几个方面：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;知识库&lt;/strong&gt;：客户需要将业务数据统一收集处理，形成知识库，以便提供给LLM进行使用&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;应用中心&lt;/strong&gt;：B端客户需要开箱即用的产品，解决实际工作业务中碰到的问题&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;用户权限&lt;/strong&gt;：系统提供企业级灵活可控的权限管理，方便企业客户进行统一管理授权。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;多租户&lt;/strong&gt;：多租户体系架构是必不可少的，可以保证数据以Schema级别进行隔离，保障数据安全以及上层应用的灵活输出支撑。&lt;/li&gt;
  &lt;li&gt;…&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;而从技术侧考虑，技术人员需要关注的是：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;非结构化数据的处理&lt;/strong&gt;：平台需要支持多种多样的非结构化数据的提取处理工作，将整个文档内容进行chunking、embedding进入数据库，以便进行搜索
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;文件类型广度&lt;/strong&gt;：提供众多的非结构化数据文档(PDF/PPT/WORD等)的提取支持，是打动B端客户的有利吸引点，&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;文件解析精度&lt;/strong&gt;：以PDF/PPT/Word为首的文档解析工作困难重重，如何在解析的工作上更进一步，从根源上减少模型在利用已知数据的幻觉问题&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;任务调度&lt;/strong&gt;：数据的处理依靠稳定的任务调度平台，保证数据处理的最终有序执行。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;模型服务&lt;/strong&gt;：从LLM大语言模型、Reranker模型、embedding、OCR模型、视觉模型等等，&lt;strong&gt;保证模型的幂等输出&lt;/strong&gt;，为上层应用提供稳定可靠的服务支撑。
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;LLM模型&lt;/strong&gt;：提供一系列&lt;strong&gt;Agent服务&lt;/strong&gt;，保证上层业务能够灵活调用大模型获取满意的结果&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;ReRanker模型&lt;/strong&gt;：重排序模型是问答二阶段召回提高准确率的关键手段，不可忽虑&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;Embedding模型&lt;/strong&gt;：向量化嵌入，提供对知识文本的表征提取向量工作，不可忽虑&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;OCR/视觉模型&lt;/strong&gt;：辅助非结构化数据提取在规则提取不满足的情况下，启动OCR及视觉模型，增强非结构化数据的提供效果&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;向量数据库(VectorDB)&lt;/strong&gt;: 需要结合实际业务诉求，从性能/空间/生态等多方面考量VectorDB等选型&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;技术的角度拆分，其实技术人员关注的点非常的多，每一项工作其实都可以是独立的中间件产品，要把这些全部整合到一块，并非易事。&lt;/p&gt;

&lt;h2 id=&quot;3微服务分布式云原生&quot;&gt;3、微服务/分布式/云原生？&lt;/h2&gt;

&lt;p&gt;写过Java的估计对上面这三个名词都已经滚瓜乱熟了，我记得很早之前，说面试你如果不会微服务，那都找不到工作(PS:现在好像不管你会什么，也同样都找不到)😂。&lt;/p&gt;

&lt;p&gt;对于AI应用，可能更多的软件生态是由Python带动起来的，包括一些工具库LangChain、LlamaIndex等都是Python，虽然Java中也不乏有一些，比如LangChain4j、Spring-AI等组件，都是后起之秀，在整个生态稳定性等方面确实是落后了一节。&lt;/p&gt;

&lt;p&gt;但可能很多人都在用过LangChain等框架后有一个共识，那就是当作工具用没有问题，但是上生产？问题太多了。我觉得主要的几个点：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;LangChain的过度封装，对于应用层而言，不管是Agent，还是RAG，其实蛮简单的一件事情，和大模型API接口对接就好了，但是你去看LangChain的源码，整个调用链路封装的极其复杂，改都没法改。&lt;/li&gt;
  &lt;li&gt;上层的业务需求变化太大了，有时候是需要结合自己公司的实际业务情况来进行处理的，这种情况下，还不如自己写来的快，其实调用的链路并不复杂&lt;/li&gt;
  &lt;li&gt;就稳定性/事务/数据一致性而言，Python作为企业服务接口主语言是否合适呢？&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;而我们今天讨论的是整个产品的技术架构的选择，其实在上面业务功能/技术组件抽象那一节，我们已经拆分了功能和技术点，从技术点去看，这已经是一个集众多服务于一体的综合技术解决方案了。在应用层面的功能，我们是否还需要像以前那样，整一套微服务架构出来来开发业务功能？&lt;/p&gt;

&lt;p&gt;我的个人看法是：&lt;strong&gt;根据团队配置，微服务可用可不用。但是应用程序必须天然分布式，支持横向扩展集群，弹性伸缩。&lt;/strong&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;目前这个环境，项目搞微服务，最后的困境可能就是所有服务都是你一个人负责，写完a服务写b服务，再来个rpc调用，还要考虑数据熔断、可用性等等，小团队我觉得完全没必要折腾！&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;主要考虑的点：&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;1、海量非结构化数据处理的提效&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;在处理RAG产品类中，非结构化数据的处理除了快速解析之外，还需要将文本进行向量化，而我们在技术架构中需要能够快速的处理这些文件，通过Pipeline的方式，将非结构化数据最终存储到向量数据库中，这里面传统的做法不得不用消息中间件MQ，而应用层面的程序则可以通过考虑弹性伸缩的方式，扩充消费节点，以提高整体的处理效率&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;2、海量向量数据的存储/计算召回效率&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;当我们对非结构化数据进行提取后，需要经过Embedding模型进行向量化，这里面还涉及到文本的Chunking分块，所以底层向量数据的存储和计算必然是一个需要更全面的考虑向量数据库中间件，这其中包括：向量召回的性能、数据的存储/备份、多租户Schema级别数据权限等等&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;3、数据最终一致性&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;数据的Embedding处理、大模型调度扣费、缓存等等，在目前已经众多服务组件拆分的情况下，整个数据的处理任务我觉得需要保证数据的最终一致性，在分布式场景下，多节点处理时需要特别注意。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;4、应用功能原子性（云原生）&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;整个应用层的功能，我觉得需要&lt;strong&gt;保持独立，并且保障稳定性&lt;/strong&gt;，这点其实我觉得在私有化部署/交付的环节比较奏效。如果你是一名运维或者主力开发者，在一个完全内网隔离的环境下部署时，你会体会到这种便捷。&lt;/p&gt;

&lt;p&gt;总之，我觉得在应用层面服务，服务端应该做的是：&lt;strong&gt;减少配置、轻量化、稳定&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;4编程语言中间件选择&quot;&gt;4、编程语言/中间件选择？&lt;/h2&gt;

&lt;p&gt;我们团队目前的开发语言是Java+Python的组合，主要有职责分工：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Java：上层业务应用的API接口，任务调度、数据处理等等&lt;/li&gt;
  &lt;li&gt;Python：和模型、数据处理、NLP等相关任务以接口的形式开放出来，API接口是无状态的，所有的数据状态流转都在Java端实现&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;这里面很多开发可能会有一些担忧，对于Java语言的选择，是否在目前的RAG/大模型领域合适？其实最困惑的就是非结构化数据的处理，可能很多开发者看到目前开源的众多组件或者平台，都是Python的主技术栈，认为Java处理不了，其实这是完全有误区的，对于最难处理的PDF文件提取，&lt;strong&gt;Apache PDFBox&lt;/strong&gt;绝对是值得你深挖的一个组件，当然Python本来就擅长数据处理/分析，可以根据团队的配置进行执行选择，这里面我觉得主要考虑的几个点：&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;1、团队人员配置&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;根据团队当前的主流编程语言去做技术架构上的选型和决策，并没有绝对意义上的以哪个编程语言为主，Java、Python、Go、NodeJS、TypeScript等等都可以。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;2、软件生态&amp;amp;技术成熟度&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;上层应用产品的开发，肯定首先要考虑有哪些成熟的中间件和组件，来开发完成这一众多的需求，总不能从0到1造轮子，造轮子固然能提升开发人员的水平技能，但是在AI日益发展的今天，为公司产品尽早的找到PMF才是首要任务。需要综合考虑。&lt;/p&gt;

&lt;p&gt;其他的编程语言我不了解，就非结构化数据的解析这一块，其实Python和Java都相对更加丰富和稳 定。&lt;/p&gt;

&lt;p&gt;Java语言中比较好用的包括：Apache PDFBox、POI、Tika&lt;/p&gt;

&lt;p&gt;Python中包括：PyMuPDF、pdfplumber、pypdf、camelot、python-docx等等&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;3、稳定性/集群/高可用&lt;/strong&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;嗯，这里没有高并发，因为大家都没卡😂&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;大模型的产品相比较传统的业务在这点上并没有 太多的区别，稳定性/集群等特点也是需要的，技术人员在选择中间件时，也应当考虑这一点。&lt;/p&gt;

&lt;p&gt;例如MQ消息中间件、缓存Redis等等&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;4、部署实施/交付&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;没错，最后一步部署实施这个环节也需要考虑，Docker确实能带来极大的便利，但是成本也是需要考量的，目前的Python生态打包整个Docker，压缩包动辄2、3G起步，其实也是蛮头疼的，如果你是使用K8s调度来部署，k8s拉取一个10G的镜像也不是那么快的😂&lt;/p&gt;

&lt;h2 id=&quot;5总结&quot;&gt;5、总结&lt;/h2&gt;

&lt;p&gt;AI应用是一个需要快速试错、功能强大的某一个点去突破，技术架构上，也应当考虑整体的开发效率、生态等等。&lt;/p&gt;

&lt;p&gt;这让我想起来十几年前的jQuery，一经面世，得到众多开发者的喜爱，经典名言：&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Write Less, Do More!!!
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;在大模型日益健壮发展的同时，我们的技术架构，是否也应该做一次瘦身呢？&lt;/p&gt;</content><author><name>八一菜刀</name></author><category term="大模型" /><category term="RAG实践" /><category term="TorchV" /><category term="RAG概述" /><category term="RAG" /><category term="大模型" /><category term="LLM" /><summary type="html">1、前言</summary></entry><entry><title type="html">创业：大模型RAG系统三个月的开发心得和思考</title><link href="http://localhost:4000/2024/04/01/torchv-summary-01/" rel="alternate" type="text/html" title="创业：大模型RAG系统三个月的开发心得和思考" /><published>2024-04-01T00:00:00+08:00</published><updated>2024-04-01T00:00:00+08:00</updated><id>http://localhost:4000/2024/04/01/torchv-summary-01</id><content type="html" xml:base="http://localhost:4000/2024/04/01/torchv-summary-01/">&lt;h1 id=&quot;1-前言&quot;&gt;1. 前言&lt;/h1&gt;

&lt;p&gt;自从和&lt;a href=&quot;https://www.luxiangdong.com/&quot;&gt;员外&lt;/a&gt;上家公司离职后，我们就自己搞公司投入到了RAG大模型的AI产品应用的开发中，这中间有一个春节，前后的总时间大概是三个月左右，在这三个月期间，基本是昼夜兼程啊，到今天3月底结束，产品目前看是有了一个基础的雏形。&lt;/p&gt;

&lt;p&gt;在这期间，员外负责整个产品的营销、商业客户的洽谈等方面的内容，我和阿包负责整体的技术架构搭建，代码从0-1的编写，我们是在24年1月26，产品初步上线了一个版本，开始接受企业客户的试用，这让我们接受到了大量的需求，以及我们产品在目前的市场环境中还存在哪些竞争力不足需要改进的地方。&lt;/p&gt;

&lt;p&gt;三个月时间过去了，在我们的TorchV AI 产品初步成型之际，和大家分享一下开发RAG、LLM系统以来的一些心得和经验。&lt;/p&gt;

&lt;h1 id=&quot;2-rag简介&quot;&gt;2. RAG简介&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/rag/torchv/summary-01/IMG_7625.jpeg&quot; alt=&quot;图1-RAG基础架构&quot; /&gt;&lt;/p&gt;

&lt;p&gt;RAG(检索增强生成)名词一开始来源于&lt;strong&gt;2020年&lt;/strong&gt;的一片论文《&lt;a href=&quot;https://arxiv.org/abs/2005.11401&quot;&gt;Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks&lt;/a&gt;》，旨在为大语言模型（LLM）提供额外的、来自外部知识源的信息。这样，LLM 在生成更精确、更贴合上下文的答案的同时，也能有效减少产生误导性信息的可能。&lt;/p&gt;

&lt;p&gt;可以说在目前大模型井喷的今天，RAG作为一项为密集型知识NLP任务的处理指明了方向，配合AI大模型，让世界发生了翻天覆地的变化，数以万计的开发者都涌入这个赛道，同时竞争。&lt;/p&gt;

&lt;p&gt;我们知道LLM目前存在的一些问题和挑战：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;我自己理解LLM大模型本质就是一个二进制文件，所有的知识都通过压缩技术全部压缩在一个/多个GB的二进制文件中，最终在获取数据的时候，通过LLM的模型架构，推理能力，将所有的知识信息又生成出来。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;在没有答案的情况下提供虚假信息(胡说八道、幻觉)。&lt;/li&gt;
  &lt;li&gt;模型知识的更新成本、周期、及大模型的通用能力问题（大公司才玩的转）&lt;/li&gt;
  &lt;li&gt;数据安全和隐私等问题&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;而RAG技术的出现，正好能有效的缓解目前大模型存在的一些问题，主要表现方面如下：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;经济高效的处理知识&amp;amp;开箱即用：只需要借助信息检索&amp;amp;向量技术，将用户的问题和知识库进行相关性搜索结合，就能高效的提供大模型不知道的知识，同时具有&lt;strong&gt;权威性&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;有效避免幻觉问题：虽然无法100%解决大模型的幻觉问题，但通过RAG技术能够有效的降低幻觉，在软件系统中结合大模型提供幂等的API接口就可以发挥大模型的重大作用&lt;/li&gt;
  &lt;li&gt;数据安全：企业的数据可以得到有效的保护,通过私有化部署基于RAG系统开发的AI产品，能够在体验AI带来的便利性的同时，又能避免企业隐私数据的泄漏。&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;3-rag技术架构思考&quot;&gt;3. RAG技术&amp;amp;架构思考&lt;/h1&gt;

&lt;p&gt;既然我们知道，RAG作为密集型知识库的处理和大模型配合起来有着天然优势，那么如何做好RAG的开发？&lt;/p&gt;

&lt;p&gt;RAG应用的&lt;strong&gt;基础技术核心&lt;/strong&gt;是：&lt;strong&gt;让大模型依靠现有的数据(PDF/WORD/Excel/HTML等等)精准的回答用户的问题&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;这是最基础的功能，同时也是最低要求，任何做RAG领域的AI应用产品，技术层面都需要去突破解决的技术难题。&lt;/p&gt;

&lt;p&gt;注意&lt;strong&gt;两个核心&lt;/strong&gt;点：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;📁 &lt;strong&gt;依赖现有的知识库&lt;/strong&gt;：依赖客户本身的数据是为了给大模型提供强有力的数据支撑,&lt;strong&gt;避免大模型胡说八道&lt;/strong&gt;,企业私有的数据大模型并没有将数据纳入模型进行训练,所以大模型对于企业私有的数据及相关问题,大模型不可能知道，即使大模型能回答你这个领域的问题，那也是因为你这个问题在大模型训练的数据集中早就存在了，而且是公开的数据集和问题，而&lt;strong&gt;企业私有的数据(财务报告、隐私数据等)大模型是不可能拥有的&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;🏹 &lt;strong&gt;精准命中回答&lt;/strong&gt;：一旦客户将自己的私有数据上传了之后,我们要做的就是依靠此数据&lt;strong&gt;精准回答用户的问题&lt;/strong&gt;，而要做到精准回答命中,技术人员需要做多方面的努力💪。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;技术人对于RAG应用考虑的最核心的就是这两点，而技术测为了要实现这一个&lt;strong&gt;目标&lt;/strong&gt;，其覆盖的知识面以及技术难度都是非常大的。&lt;/p&gt;

&lt;p&gt;我很早之前参考大模型的技术架构发展，为RAG画了一张类似的图，如下：&lt;img src=&quot;/assets/images/rag/torchv/summary-01/image-20240330154925101.png&quot; alt=&quot;图2-RAG发展架构树&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这里面我为做RAG系统的总结为三颗树，LLM大模型是土壤，主要为：&lt;strong&gt;数据工程&lt;/strong&gt;、&lt;strong&gt;检索生成&lt;/strong&gt;、&lt;strong&gt;业务系统&lt;/strong&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;这里面并没有把对模型的微调放入进来，当我们把基础工程做到80分后，也许对Embedding模型、Chat模型等微调工作会加入进来，针对特定的业务场景做优化。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;数据工程:&lt;/strong&gt; 知识库的形式丰富多彩,这其中配合RAG我们要做的事情非常多，包括文件类型、格式、分割策略、知识类型、索引方式等等&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;检索生成:&lt;/strong&gt;当我们处理完成数据后，配合大模型需要进行检索生成，而在这个过程中，包括：Prompt工程、算法策略、检索方式、中间件、大模型、查询处理等内容&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;业务系统&lt;/strong&gt;: 这是配合商业行为所衍生的业务系统&amp;amp;上层产品应用，包括租户、计费、开放平台、洞察、运营等业务系统，这些业务系统在TorchV AI的产品体系都一一体现&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;通过上面的图，我们大概就能知道，&lt;strong&gt;RAG+LLM大模型系统的产品开发，是一个综合性非常强的工作内容，这就和大模型的训练一样，整个工程庞大繁杂，是一个系统性工程&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;如果我们把三颗树中的每一项都作为一个技术因子，不同的步骤处理优化，都会影响着最终外部的商业的影响力，这就会产生量变到质变的转变。&lt;/p&gt;

&lt;p&gt;假设：&lt;strong&gt;我们把数据工程和检索工程所有的步骤在技术层面提升了10%，那么我们在和同类竞品去竞争时，我们的优势是多大呢？&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;31-数据工程&quot;&gt;3.1 数据工程&lt;/h2&gt;

&lt;p&gt;在大模型圈子里，经典名言：&lt;strong&gt;Garbage in and garbage out&lt;/strong&gt;，意思显而易见，你给大模型送的数据质量越高，那么大模型的响应回答效果就越好，反之，如果你丢垃圾给大模型，那么大模型也会给你返回垃圾～&lt;/p&gt;

&lt;p&gt;所以从这点来看，上层的应用开发者，要做好知识库类型的产品，&lt;strong&gt;数据工程&lt;/strong&gt;绝对是第一道拦路虎，从数据集的不同领域进行分类,目前存在非常多的数据格式&lt;/p&gt;

&lt;p&gt;这里面包含的多种不同的挑战&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;常见文件解析&lt;/strong&gt;：基于文件类型的数据集是最常见的,也是使用最广的,例如(PDF/WORD/Excel/CSV/Html/Markdown)等格式&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;关系型/NoSQL数据库&lt;/strong&gt;: 用户的数据全部存储在数据库中间件中，例如MySQL/Postgres等，NoSQL数据库中，这种数据源的提取到是不难，开发者只需要根据不同的数据库标准协议进行对接抽取即可，要做的是适配不同的数据库类型&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;网络数据集&lt;/strong&gt;：对于网络数据集的处理，那么就需要开发者精通爬虫之道,而网络上的数据集种类也是非常广的，普通的W3C网页(格式种类复杂繁多)，视频、音频等等信息&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;不同类型的数据提取：&lt;/strong&gt;包括文本、图片、表格、视频等，单单一个表格数据的在不同的文件格式的处理，就需要花费大量的精力去优化&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;提取方式的类别&lt;/strong&gt;：传统的软件工程、OCR、大模型等等&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;分割策略&lt;/strong&gt;：分割策略在RAG的技术体系中有着举足轻重的地位,分割的不好，会在信息检索(IR)的过程中丢失语义，包括：语义分割、大模型分割、按固定Token分割、文档结构分割等等&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Embedding索引构建：&lt;/strong&gt;除了给每一个chunk块构建向量索引，元数据、标题、概要总结等等也会对系统准不准有不同的要求，同时还要和上层的业务进行结合。&lt;/li&gt;
  &lt;li&gt;More…&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;在数据工程这棵树上，所有的技术发展都不是停滞不前的，这里仅仅只是列了一些基础的树枝，我相信在大模型AI井喷爆发的今天，会更快推进数据工程(ETL)的发展。&lt;/p&gt;

&lt;h2 id=&quot;32-检索生成&quot;&gt;3.2 检索生成&lt;/h2&gt;

&lt;p&gt;当我们把所有的知识数据处理完毕，借助大模型来构建一个Chat系统时，信息检索技术则是必然要用到的&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;从这里我们好像发现，做RAG，无非就是做搜索?&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;在目前的RAG检索的技术体系中，最普遍的无非两种：关键词和向量语义检索&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;关键词检索：基于类似BM25这类词频倒排技术，通过统计关键词的方式来执行搜索，缺点是无语义信息&lt;/li&gt;
  &lt;li&gt;向量语义检索：通过将所有知识片段通过BERT等预训练语言模型进行表征提取，表示为多维的向量数据，通过KNN/ANN算法搜索获取结果。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;当然，在目前的很多向量数据库中间件中，这两类检索引擎都得到了支持，或者是混合检索也是一种重要的技术手段。&lt;/p&gt;

&lt;p&gt;在整个检索生成的过程中，这棵树同样关注的技术细节也非常的多，如下：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Prompt工程&lt;/strong&gt;：和大模型对话，技术人员必须掌握的Prompt工程，通过FewShot、CoT、ZeroShot等技术，针对不同的业务场景能发挥重大的作用，开发人员需要根据具体的业务场景来调试，同时也是和大模型对接，&lt;strong&gt;解决幂等性&lt;/strong&gt;的重要手段&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;LLM大模型&lt;/strong&gt;：glm3/4、百川、千问、月之暗面、gpt3.5、gpt4等等大模型，在不同的场景、能力各有侧重，进行深度的业务调试/适配同样重要。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;检索召回过程处理&lt;/strong&gt;：多轮对话、查询重写、多跳、多路召回、子查询等等，伴随业务场景的深入，每一个Chain的环节保证稳定可靠，不是轻松的事&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;中间件&lt;/strong&gt;：系统稳定高可用、可扩展离不开中间件的支持，如缓存、消息队列、向量数据库、图数据库等等都是必不可少的&lt;/li&gt;
  &lt;li&gt;More:….&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;在检索生成的这棵树上，和数据工程密切配合不可分割，都是在降低大模型幻觉的道路上深挖技术细节。&lt;/p&gt;

&lt;h1 id=&quot;4-技术产品领导驱动商业的发展&quot;&gt;4. 技术&amp;amp;产品领导驱动商业的发展&lt;/h1&gt;

&lt;p&gt;做RAG这类AI应用开发以来，感受最深的是和之前做产品/项目并不相同，一方面是技术栈发展较新，新技术带来的技术变革存在非常大的挑战，有了大模型之后，需求&amp;amp;想法也是五花八门，另外，目前的AI应用，我觉得更多的是&lt;strong&gt;技术&amp;amp;产品来领导驱动商业的发展&lt;/strong&gt;，这和普通软件企业的开发流程或许有所不同。&lt;/p&gt;

&lt;p&gt;这里我觉得几点非常重要：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;新AI技术的迅速发展必然革新之前的软件流程和开发过程，在思想层面是必须转变。&lt;/li&gt;
  &lt;li&gt;大模型幻觉很严重，通过RAG技术解决幻觉&lt;strong&gt;做60分很容易&lt;/strong&gt;，但是把底层的能力提升到80分甚至90分，是非常难的事情，这需要一个长期累积迭代的过程。&lt;/li&gt;
  &lt;li&gt;企业客户不会为了一个只有60-70分的技术产品买单付费，对待软件编码、技术架构、产品交互等方面，产研人员需要对自己要求更高，追求完美&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;我们团队内部经过这段时间的迭代，也碰了很多客户的需求，团队的方向也是在发展中不断的进行调整。&lt;/p&gt;

&lt;p&gt;我们在成立TorchV AI时，整体架构如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/rag/torchv/summary-01/torchv.png&quot; alt=&quot;图3-TorchV架构&quot; /&gt;&lt;/p&gt;

&lt;p&gt;我们以RAG技术为核心，在上层做我们的中间件层，这里面最核心的三个：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;主要核心问题聚焦在降低大模型幻觉、不同数据源连接上面&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;TorchV IC(幂等分类器)&lt;/strong&gt;:让既定的事实数据发挥更大比重，引入尽可能多的幂等，对抗和降低LLM的幻觉;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;TorchV Actuator(执行器)&lt;/strong&gt;:优化TorchV特有风格的输出格式，包括交互界面的组装，对应用更友好;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;TorchV Connector(连接器)&lt;/strong&gt;:连接本地数据，有序解决本地化场景下数据多样性和复杂性问题.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;通过RAG技术+中间件的方式，开发出了我们的第一个产品基线TorchV Bot。通过持续的产品迭代和不同客户需求碰撞，我们的TorchV Bot基线产品的架构也初步成型。如下图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://www.luxiangdong.com/images/torchv_website/products_ai_apps.png&quot; alt=&quot;图4-TorchV.AI应用架构&quot; /&gt;&lt;/p&gt;

&lt;p&gt;主要组件拆分如下：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;RAG和Agent&lt;/strong&gt;：RAG（检索增强生成）和Agent是目前大语言模型落地到企业应用的事实标准，也是TorchV AI的核心中间件之一；&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Tenant&lt;/strong&gt;：租户系统，这是我们支起多租户PaaS/SaaS平台的基础；&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;OSS&lt;/strong&gt;：在线文件存储，包括客户上传的文件，以及从URL中导入的数据等；&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;ChatBot&lt;/strong&gt;：TorchV AI会提供一个默认的Web版问答系统，客户可以在上面对知识进行测试，对于内部使用场景，也可以直接使用；&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;数据&amp;amp;洞察分析&lt;/strong&gt;：对数据进行分析，包括客户预先设定的一些洞察条件，一旦触发条件，就会进行指定动作，如产品和服务的推荐，咨询分流等。客户在这里也可以对数据进行同步，导入到自己的系统，作为数据分析的数据基础；&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;知识库管理&lt;/strong&gt;：创建知识库，为每个知识库上传和导入文件，一旦上传，文件立即被系统处理，变成chunk（小块文本）和embedding之后的向量数据等；&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;运营后台&lt;/strong&gt;：包括计费系统、各类参数配置、对话记录查看和标注、用户权限设置和反馈处理等功能；&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;应用中心&lt;/strong&gt;：一个客户即可创建多个应用，然后通过API对接自己的原有系统，或者根据API创建新应用。除了API之外，我们还提供一键嵌入的对接方式，只需引入几行js代码，即可在客户的Web应用上开启悬浮icon，提供TorchV AI的对话能力。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;以上则是目前TorchV的产品雏形，更多细节可以访问&lt;a href=&quot;https://www.torchv.com&quot;&gt;官网:https://www.torchv.com&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&quot;5-架构编程语言的选择&quot;&gt;5. 架构&amp;amp;编程语言的选择&lt;/h1&gt;

&lt;p&gt;随着大模型LLM的爆火，包括&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;LangChain&lt;/code&gt;、&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;LlamaIndex&lt;/code&gt;等以LLM为基础的数据Python框架的出现，很多开发者在选择开发RAG系统应用时，会可能无法着手。&lt;/p&gt;

&lt;p&gt;起初在开发RAG应用的时候，也纠结过编程语言的选择，在这期间走了很多的弯路，也得到了一些教训。&lt;/p&gt;

&lt;p&gt;先说结论，TorchV.AI的产品选Java+Python作为服务端的开发语言。&lt;/p&gt;

&lt;p&gt;这里面有以下几个原因：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;员外和我都是多年的Java语言开发出生，从编码、生态等方面的了解程度，那自然是不可能抛弃Java&lt;/li&gt;
  &lt;li&gt;Python语言是无可避免的，但是在整个工程里面，职责是有分工的，&lt;strong&gt;无状态&lt;/strong&gt;的一些逻辑操作都通过Python来实现&lt;/li&gt;
  &lt;li&gt;企业级开发语言以及技术组件生态&lt;/li&gt;
  &lt;li&gt;中间件丰富程度、开发社区的健康发展&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;下图是我画的一个&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Java&lt;/code&gt; VS &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Python&lt;/code&gt;这两个编程语言在不同领域的一些特性对比。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/rag/torchv/summary-01/language.png&quot; alt=&quot;图5-编程语言选择&quot; /&gt;&lt;/p&gt;

&lt;p&gt;目前市面上开发RAG大模型应用最火的当属&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;LangChain&lt;/code&gt;、&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;LlamaIndex&lt;/code&gt;这两个框架，都是&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Python&lt;/code&gt;语言进行开发，提供了开箱即用的功能，可能在&lt;strong&gt;不超过10行代码&lt;/strong&gt;的情况下，就能轻松完成一个RAG大模型应用的demo。&lt;/p&gt;

&lt;p&gt;我们起初也是在纠结在这期间如何更好的做取舍，后来团队内部经过讨论，还是将部分的业务逻辑放在Java语言中，重写RAG过程中的一些核心逻辑和组件。&lt;/p&gt;

&lt;p&gt;这里面的思考：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;RAG架构涉及到的东西多且杂，开箱即用的LLM数据处理框架可能无法满足企业的业务诉求(需求变化多端)&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;RAG目前并没有发展成为HTTP规范一样的协议约定，所以不同的RAG过程、LLM模型等都会导致RAG的效果差异&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;国内LLM百花齐放，无法开箱即用，国内的不同需求也需要满足(本地化适配)&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;结合在开发RAG应用中涉及到的数据工程等部分逻辑，我们结合两大语言的特性，也能很轻松的勾画出一张便语言级别的架构图，涵盖了在企业开发、业务场景落地时，如何快速的适配上层应用的需求。如下图所示：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/rag/torchv/summary-01/rag_languages.png&quot; alt=&quot;图6-基于语言能力级别的RAG架构示意图&quot; /&gt;&lt;/p&gt;

&lt;p&gt;在这种图中，我们可以清晰的看到，不同的任务&amp;amp;需求，职责分工是比较明确的。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Java：使用Java生态时，针对业务系统的数据一致性，分布式、鉴权、限流等企业应用接口的特性开发，目前都有非常成熟的解决方案&lt;/li&gt;
  &lt;li&gt;Python：涉及到无状态的服务时，支撑上层应用的处理，包括数据工程、Chat模型、数据处理、微调等系统工程，那么用Python是毫无疑问&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;在这里，当我们使用应用开发时，挑选编程语言来开发应用服务，优先考虑的是生态和稳定性。&lt;/p&gt;

&lt;p&gt;当然，这里面并没有唯一的标准，根据自己的实际情况出发来选择是最优的，以上仅仅只是分享一下我的看法。&lt;/p&gt;

&lt;h1 id=&quot;6-总结&quot;&gt;6. 总结&lt;/h1&gt;

&lt;p&gt;好了，全文完，做一个总结：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;RAG、LLM等AI产品的开发是日新月异的，技术栈体系会飞速发展,对于公司而言，小步快跑，快速试错可能是非常重要的&lt;/li&gt;
  &lt;li&gt;应用场景目前仅仅只是聚焦在知识密集型任务，未来随着技术的发展，会扩展到更多的行业中。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;TorchV.AI目前是刚起步阶段，也欢迎更多的企业客户试用，合作！！！&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;如果您有商务合作需求：&lt;/p&gt;

  &lt;p&gt;请扫码添加以下微信（员外🔥TorchV），并请您告知您的称呼 和 企业名称 。
&lt;img src=&quot;https://www.torchv.com/img/consociation/yuanwai.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;我们的官网地址：&lt;a href=&quot;https://www.torchv.com&quot;&gt;https://www.torchv.com&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&quot;7-references&quot;&gt;7. References&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.torchv.com&quot;&gt;https://www.torchv.com&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.luxiangdong.com&quot;&gt;https://www.luxiangdong.com&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/2005.11401&quot;&gt;https://arxiv.org/abs/2005.11401&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>八一菜刀</name></author><category term="大模型" /><category term="RAG实践" /><category term="TorchV" /><category term="RAG概述" /><category term="RAG" /><category term="大模型" /><category term="LLM" /><summary type="html">1. 前言</summary></entry><entry><title type="html">TorchV的RAG实践分享(三):解析llama_index的数据存储结构和召回策略过程</title><link href="http://localhost:4000/2024/01/14/torchv-rag-3/" rel="alternate" type="text/html" title="TorchV的RAG实践分享(三):解析llama_index的数据存储结构和召回策略过程" /><published>2024-01-14T00:00:00+08:00</published><updated>2024-01-14T00:00:00+08:00</updated><id>http://localhost:4000/2024/01/14/torchv-rag-3</id><content type="html" xml:base="http://localhost:4000/2024/01/14/torchv-rag-3/">&lt;h1 id=&quot;1前言&quot;&gt;1.前言&lt;/h1&gt;

&lt;p&gt;LlamaIndex是一个基于LLM的数据处理框架，在RAG领域非常流行，简单的几行代码就能实现本地的文件的对话功能，对开发者提供了极致的封装，开箱即用。&lt;/p&gt;

&lt;p&gt;本文以官方提供的最简单的代理示例为例，分析LlamaIndex在数据解析、向量Embedding、数据存储及召回的整个源码过程。&lt;/p&gt;

&lt;p&gt;通过学习框架的源码也能让开发者们在实际的企业大模型应用开发中，对RAG有一个更清晰的了解和认知。&lt;/p&gt;

&lt;p&gt;本次选用的技术组件：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;llm&lt;/strong&gt;：OpenAI&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Embedding&lt;/strong&gt;：OpenAI&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;VectorDB&lt;/strong&gt;：ElasticSearch&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;官方代码示例如下：&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
&lt;span class=&quot;c1&quot;&gt;# 1.构建向量数据库存储对象实例
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vector_store&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ElasticsearchStore&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;index_name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;my_index&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;es_url&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;http://localhost:9200&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;storage_context&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;StorageContext&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;from_defaults&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vector_store&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vector_store&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# 加载本地的数据集
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;documents&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SimpleDirectoryReader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'data'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# 构建索引
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;index&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;VectorStoreIndex&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;from_documents&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;documents&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;storage_context&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;storage_context&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# 服务对象，构建query引擎
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;service_context&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ServiceContext&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;from_defaults&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;llm&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;OpenAI&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;query_engine&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;as_query_engine&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;service_context&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;service_context&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# 问问题
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;resp&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;query_engine&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;query&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;住院起付线多少钱?&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# 响应答案
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;resp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;2处理过程&quot;&gt;2.处理过程&lt;/h1&gt;

&lt;h2 id=&quot;21-数据处理过程&quot;&gt;2.1 数据处理过程&lt;/h2&gt;

&lt;p&gt;在数据处理的过程中，主要包含几个核心的步骤：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;初始化向量存储引擎，目前向量数据库类型非常多，笔者本机跑了一个es的docker镜像，这里就选择es了&lt;/li&gt;
  &lt;li&gt;读取数据，数据格式包括：PDF、WORD、TXT等等文本数据&lt;/li&gt;
  &lt;li&gt;在数据读取完成后，会对文档内容进行分割，然后Embedding(调用embedding模型)存储入库&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;211-处理加载不同的文件类型构建document&quot;&gt;2.1.1 处理加载不同的文件类型(构建Document)&lt;/h3&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SimpleDirectoryReader&lt;/code&gt;是llamaindex提供的一个基于文件夹的读取器类，会根据文件夹中的文件扩展后缀类型自动加载数据&lt;/p&gt;

&lt;p&gt;主要支持的文件数据类型如下：&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;DEFAULT_FILE_READER_CLS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Type&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;BaseReader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;.hwp&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;HWPReader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;.pdf&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;PDFReader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;.docx&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DocxReader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;.pptx&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;PptxReader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;.ppt&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;PptxReader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;.pptm&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;PptxReader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;.jpg&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ImageReader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;.png&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ImageReader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;.jpeg&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ImageReader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;.mp3&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;VideoAudioReader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;.mp4&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;VideoAudioReader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;.csv&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;PandasCSVReader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;.epub&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;EpubReader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;.md&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MarkdownReader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;.mbox&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MboxReader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;.ipynb&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;IPYNBReader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;


&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;SimpleDirectoryReader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;BaseReader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;Simple directory reader.

    Load files from file directory.
    Automatically select the best file reader given file extensions.

    Args:
        input_dir (str): Path to the directory.
        input_files (List): List of file paths to read
            (Optional; overrides input_dir, exclude)
        exclude (List): glob of python file paths to exclude (Optional)
        exclude_hidden (bool): Whether to exclude hidden files (dotfiles).
        encoding (str): Encoding of the files.
            Default is utf-8.
        errors (str): how encoding and decoding errors are to be handled,
              see https://docs.python.org/3/library/functions.html#open
        recursive (bool): Whether to recursively search in subdirectories.
            False by default.
        filename_as_id (bool): Whether to use the filename as the document id.
            False by default.
        required_exts (Optional[List[str]]): List of required extensions.
            Default is None.
        file_extractor (Optional[Dict[str, BaseReader]]): A mapping of file
            extension to a BaseReader class that specifies how to convert that file
            to text. If not specified, use default from DEFAULT_FILE_READER_CLS.
        num_files_limit (Optional[int]): Maximum number of files to read.
            Default is None.
        file_metadata (Optional[Callable[str, Dict]]): A function that takes
            in a filename and returns a Dict of metadata for the Document.
            Default is None.
    &quot;&quot;&quot;&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;supported_suffix&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DEFAULT_FILE_READER_CLS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;keys&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;//&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;....&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;总共支持了16个文件数据类型，整理到表格如下：&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;文件类型&lt;/th&gt;
      &lt;th&gt;依赖组件&lt;/th&gt;
      &lt;th&gt;说明&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;hwp&lt;/td&gt;
      &lt;td&gt;olefile&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;pdf&lt;/td&gt;
      &lt;td&gt;pypdf&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;docx&lt;/td&gt;
      &lt;td&gt;docx2txt&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;pptx、pptm、ppt&lt;/td&gt;
      &lt;td&gt;python-pptx、transformers、torch&lt;/td&gt;
      &lt;td&gt;用到一些模型，对数据进行理解、提取&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;jpg、png、jpeg、&lt;/td&gt;
      &lt;td&gt;sentencepiece、transformers、torch&lt;/td&gt;
      &lt;td&gt;用到一些模型，对数据进行理解、提取&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;mp3、mp4&lt;/td&gt;
      &lt;td&gt;whisper&lt;/td&gt;
      &lt;td&gt;用到一些模型，对数据进行理解、提取&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;csv&lt;/td&gt;
      &lt;td&gt;pandas&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;epub&lt;/td&gt;
      &lt;td&gt;EbookLib、html2text&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;md&lt;/td&gt;
      &lt;td&gt;无&lt;/td&gt;
      &lt;td&gt;本地流直接open，读取文本&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;mbox&lt;/td&gt;
      &lt;td&gt;bs4、mailbox&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;ipynb&lt;/td&gt;
      &lt;td&gt;nbconvert&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;整个Reader类的UML类图设计如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/rag/torchv/rag-3/llamaindex-reader-uml.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;所有文件数据类型的Reader，通过&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;load_data&lt;/code&gt;方法，最终得到该文档的&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Document&lt;/code&gt;对象集合，&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Document&lt;/code&gt;类是LlamaIndex框架的处理文档的核心类对象,从该类的结构设计来看，我们可以总结一下：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;核心字段&lt;/strong&gt;：&lt;strong&gt;id(文档唯一id)&lt;/strong&gt;、&lt;strong&gt;text(文本内容)&lt;/strong&gt;、&lt;strong&gt;embedding(向量float浮点型集合)&lt;/strong&gt;、&lt;strong&gt;metadata(元数据)&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;BaseNode提供了一个&lt;strong&gt;树结构&lt;/strong&gt;的设计，对于一篇文档而言，从多级标题划分来看，树结构能更好的描述一篇文档的基础结构&lt;/li&gt;
  &lt;li&gt;Document提供了一些外部应用框架适配的方法，比如：LangChain、EmbedChain等等&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/rag/torchv/rag-3/document.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;最终构建完成所有的Document信息后，我们可以看到下面一个结构信息&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;本示例程序，使用的是一个PDF文件，由于我们并未指定分割等策略，LlamaIndex对于PDF文件是以Page为单位，进行切割，最终将所有的Document对象存储进入向量数据库&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/rag/torchv/rag-3/image-20240114153311229.png&quot; alt=&quot;image-20240114153311229&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;212-构建向量数据库索引index&quot;&gt;2.1.2 构建向量数据库索引(Index)&lt;/h3&gt;

&lt;p&gt;当本地数据集处理完成，得到一个&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Document&lt;/code&gt;集合的时候，此时，这需要构建向量数据库的索引，主要是包含几个过程：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;调用不同的向量数据库中间件，构建集合索引，对于ES来说，则是创建Index&lt;/li&gt;
  &lt;li&gt;调用Embedding模型(基于OpenAI提供的&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;text-embedding-ada-002&lt;/code&gt;模型)，将Document对象集合中的text文本，进行向量化处理并赋值&lt;/li&gt;
  &lt;li&gt;将&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Document&lt;/code&gt;集合的对象值(text、embedding、metadata)存储进入向量数据库&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;在LlamaIndex创建ES的向量索引结构中，初始情况下，核心字段也是前面我们提到的&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Document&lt;/code&gt;类中的几个核心字段(id、embedding、content、metadata)，如下图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/rag/torchv/rag-3/image-20240114164439411.png&quot; alt=&quot;image-20240114164439411&quot; /&gt;&lt;/p&gt;

&lt;p&gt;但是在Document对象遍历结束后，在数据存储阶段，考虑到元数据的信息，LlamaIndex会扩充metadata元数据的字段，如下图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/rag/torchv/rag-3/image-20240114164647308.png&quot; alt=&quot;image-20240114164647308&quot; /&gt;&lt;/p&gt;

&lt;p&gt;元数据信息会将文档的信息提取出来，包括页码、文件大小、文件名称、创建日期等等信息&lt;/p&gt;

&lt;p&gt;最终在本地数据集的情况下，LlamaIndex创建的ES数据索引结构最终就会变成下面这种结构形式：&lt;/p&gt;

&lt;div class=&quot;language-json highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;mappings&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;properties&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
            &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;content&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;type&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;text&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
            &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
            &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;embedding&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;type&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;dense_vector&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;dims&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1536&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;index&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;similarity&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;cosine&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
            &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
            &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;metadata&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;properties&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;_node_content&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                        &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;type&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;text&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                        &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;fields&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                            &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;keyword&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                                &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;type&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;keyword&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                                &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;ignore_above&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;256&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                            &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                        &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;_node_type&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                        &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;type&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;text&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                        &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;fields&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                            &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;keyword&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                                &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;type&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;keyword&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                                &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;ignore_above&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;256&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                            &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                        &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;creation_date&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                        &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;type&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;date&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;doc_id&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                        &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;type&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;keyword&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;document_id&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                        &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;type&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;keyword&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;file_name&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                        &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;type&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;text&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                        &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;fields&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                            &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;keyword&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                                &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;type&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;keyword&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                                &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;ignore_above&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;256&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                            &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                        &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;file_path&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                        &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;type&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;text&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                        &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;fields&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                            &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;keyword&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                                &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;type&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;keyword&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                                &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;ignore_above&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;256&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                            &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                        &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;file_size&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                        &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;type&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;long&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;file_type&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                        &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;type&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;text&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                        &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;fields&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                            &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;keyword&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                                &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;type&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;keyword&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                                &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;ignore_above&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;256&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                            &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                        &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;last_accessed_date&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                        &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;type&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;date&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;last_modified_date&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                        &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;type&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;date&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;page_label&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                        &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;type&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;text&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                        &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;fields&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                            &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;keyword&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                                &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;type&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;keyword&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                                &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;ignore_above&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;256&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                            &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                        &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;ref_doc_id&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                        &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;type&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;keyword&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
            &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;数据Index定义完成，Document对象存储进入向量数据库，此时，我们的数据集结构如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/rag/torchv/rag-3/image-20240114173127581.png&quot; alt=&quot;image-20240114173127581&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;22-问答获取答案&quot;&gt;2.2 问答获取答案&lt;/h2&gt;

&lt;p&gt;在获取答案的过程中，主要包含几个核心的步骤：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;构建用户查询Query，对query进行Embedding处理，召回Topk的相似片段内容。&lt;/li&gt;
  &lt;li&gt;组装Prompt工程内容，发送大模型获取答案&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;221-召回查询获取topk&quot;&gt;2.2.1 召回查询获取TopK&lt;/h3&gt;

&lt;p&gt;首先，在RAG的查询阶段，不管是使用那个向量数据库，根据数据库的类型，将用户的query语句进行Embedding后，再构建数据库的查询条件，如下图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/rag/torchv/rag-3/image-20240114155247333.png&quot; alt=&quot;image-20240114155247333&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这里面会包含几个核心的参数：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;embedding：knn查询的浮点型向量数组值&lt;/li&gt;
  &lt;li&gt;top_k:根据knn相似度查询获取得到的topk值数量，在这个例子中，LlamaIndex默认值是2&lt;/li&gt;
  &lt;li&gt;filters：过滤条件&lt;/li&gt;
  &lt;li&gt;alpha：语义&amp;amp;关键词混合检索的权重，0代表bm25算法检索，1则代表knn&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;VectorStoreQuery&lt;/code&gt;类结构定义如下：&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dataclass&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;VectorStoreQuery&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;Vector store query.&quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# knn搜索的查询Embedding浮点型数组
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;query_embedding&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Optional&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;List&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# knn搜索的top k取值
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;similarity_top_k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;doc_ids&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Optional&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;List&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;node_ids&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Optional&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;List&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;query_str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Optional&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;output_fields&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Optional&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;List&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;embedding_field&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Optional&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;mode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;VectorStoreQueryMode&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;VectorStoreQueryMode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DEFAULT&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# NOTE: only for hybrid search (0 for bm25, 1 for vector search)
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Optional&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# metadata filters
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;filters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Optional&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MetadataFilters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# only for mmr
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;mmr_threshold&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Optional&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# NOTE: currently only used by postgres hybrid search
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;sparse_top_k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Optional&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# NOTE: return top k results from hybrid search. similarity_top_k is used for dense search top k
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;hybrid_top_k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Optional&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;


&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;根据query的条件，会从向量数据库中召回获取得到topk的TextNode数组，如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/rag/torchv/rag-3/image-20240114175533596.png&quot; alt=&quot;image-20240114175533596&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;222-构建prompt发送大模型获取答案&quot;&gt;2.2.2 构建Prompt发送大模型获取答案&lt;/h3&gt;

&lt;p&gt;最终召回到引用文档内容后，剩下的就是构建整个大模型对话的Prompt工程，来看看LlamaIndex的基础Prompt是如何构建的&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/rag/torchv/rag-3/image-20240114160925472.png&quot; alt=&quot;image-20240114160925472&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/rag/torchv/rag-3/image-20240114180819057.png&quot; alt=&quot;image-20240114180819057&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;partial_format&lt;/code&gt;方法获取得到一个基础的Prompt模版信息，内容如下：&lt;/p&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;'Context information is below.
---------------------
{context_str}
---------------------
Given the context information and not prior knowledge, answer the query.
Query: {query_str}
Answer: '
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;这里有两个核心的参数：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;context_str&lt;/code&gt;: 从向量数据库召回查询的知识库引用文本数据上下文信息，从模版的设定也是告诉大模型基于知识信息进行回答&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;query_str&lt;/code&gt;：用户提问的问题&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;而最终的context_str信息，我们可以看到，如下图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/rag/torchv/rag-3/image-20240114181236770.png&quot; alt=&quot;image-20240114181236770&quot; /&gt;&lt;/p&gt;

&lt;p&gt;我们的问题是：&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;住院起付线多少钱?&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;从最终knn检索召回的文档片段来看，精准的找到了知识库的引用内容，此时，交给大模型进行回答，获取我们想要的答案结果。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/rag/torchv/rag-3/image-20240114181429648.png&quot; alt=&quot;image-20240114181429648&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;3总结&quot;&gt;3.总结&lt;/h2&gt;

&lt;p&gt;好了，本文从LlamaIndex给我们提供的基础的示例程序，基于Basic RAG的基础架构来分析数据的处理、召回响应等过程，我们可以看到LlamaIndex框架给了我们一个很好的处理流程，从这里我们可以总结如下：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;对于基础的RAG架构，有一个很好的认知，让开发者知道RAG是一个怎样的处理过程&lt;/li&gt;
  &lt;li&gt;底层的向量数据库存储结构设计和中间程序的结构设计，能够给做RAG应用的开发人员一些启发，流行的RAG框架在数据结构设计上是如何做的，这对于企业开发人员来说，架构&amp;amp;数据结构设计是有很重要的参考意义。&lt;/li&gt;
&lt;/ul&gt;</content><author><name>八一菜刀</name></author><category term="大模型" /><category term="RAG实践" /><category term="TorchV" /><category term="RAG概述" /><category term="RAG" /><category term="大模型" /><category term="LLM" /><summary type="html">1.前言</summary></entry><entry><title type="html">TorchV的RAG实践分享(二)：基于ElasticSearch的混合检索实战&amp;amp;原理分析</title><link href="http://localhost:4000/2023/12/27/torchv-rag-2/" rel="alternate" type="text/html" title="TorchV的RAG实践分享(二)：基于ElasticSearch的混合检索实战&amp;amp;原理分析" /><published>2023-12-27T00:00:00+08:00</published><updated>2023-12-27T00:00:00+08:00</updated><id>http://localhost:4000/2023/12/27/torchv-rag-2</id><content type="html" xml:base="http://localhost:4000/2023/12/27/torchv-rag-2/">&lt;h2 id=&quot;概述&quot;&gt;概述&lt;/h2&gt;

&lt;p&gt;在昨天员外分享的&lt;a href=&quot;https://mp.weixin.qq.com/s/62b8DMfbnqGDJsCx4MwXeg&quot;&gt;《TorchV的RAG实践分享（1）——RAG的定位、技术选型和RAG技术文章目录》&lt;/a&gt;一文中介绍了&lt;strong&gt;TorchV&lt;/strong&gt;的由来，也分享了我们的几个基线产品和应用架构的方向，我们想的是在创业的过程中，将我们自己的一些产品理念、技术心得都通过公众号发文的方式分享出来，更多的和行业内的专家们共同交流，这对我们自己也是一种提升和锻炼，也期待和客户一起共创成长，逐步把产品打磨好。&lt;/p&gt;

&lt;p&gt;在目前大模型应用技术架构中，通过召回上下文来回答用户的问题是解决大模型当下的幻觉问题最靠谱/经济实惠的一种解决方案,RAG检索增强技术在整个LLM技术架构体系中的作用越来越明显。而检索召回和用户的query问句的质量则直接关系到最终大模型的生成结果。在向量数据库基础设施普及的今天，仅仅通过语义搜索召回已经无法满足企业级的需求，大家发现传统的搜索技术(基于关键词、词频等相关性的搜索)的作用也显得尤为重要，混合检索也成为了目前在RAG的技术架构中的主流检索方式，混合检索通过扬长避短的方式，在不同的业务应用场景中形成了很好的互补，对于不同的业务场景需求中，可以更灵活的进行配置满足业务需要，是RAG技术架构体系中非常重要的重要一环。&lt;/p&gt;

&lt;p&gt;本文中所提到的混合检索主要是两种搜索技术的结合，主要如下：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;相关性搜索：&lt;/strong&gt; 基于BM25、TF-IDF算法，主要适用于文本精确匹配的相关性匹配搜索，它在匹配特定术语（如产品名或专业术语）方面表现出色，但对拼写错误和同义词较为敏感，可能会忽略一些重要的上下文信息。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;语义搜索：&lt;/strong&gt; 基于向量的Knn算法进行的语义检索，它能够基于用户的query语义含义进行多语言和多模态搜索，对拼写错误具有较好的容错性，但可能会忽视关键词。此外，它的效果依赖于向量嵌入的质量，并对非专业领域的术语较为敏感。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;本文针对ElasticSearch中间件来实现整个外部知识库向量的存储和计算，在RAG技术架构中的混合检索进行探索和分析，结合我们自己的实际业务情况，如何通过底层的技术驱动，完善我们的产品设计，改善整个产品流程。&lt;/p&gt;

&lt;p&gt;整篇文章主要包括：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;简介：简要概述ElasticSearch中间件以及在RAG技术架构的选型及实现&lt;/li&gt;
  &lt;li&gt;算法理论：参数在混合检索过程中涉及的算法理论知识，面向的业务场景及选择方式&lt;/li&gt;
  &lt;li&gt;召回Score分值计算：讲解ElasticSearch组件在召回计算过程中的Score分值规则及算法细节&lt;/li&gt;
  &lt;li&gt;TorchV产品驱动：技术推动我们TorchV产品的产品架构设计，如何影响产品流程&lt;/li&gt;
  &lt;li&gt;结论：整篇的总结概述及参考文章&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;elasticsearch简介&quot;&gt;ElasticSearch简介&lt;/h2&gt;

&lt;p&gt;在介绍ElasticSearch的混合检索之前，我们需要先简单回顾ElasticSearch这个中间件如何在目前AI技术场景的落地情况&lt;/p&gt;

&lt;p&gt;在目前的RAG大模型技术架构体系中，向量&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Vector&lt;/code&gt;技术已经作为大模型外挂知识库的非常重要的技术栈，向量的核心对于数据的表征(Embedding)然后执行相似度(Similarity)计算。2023年随着大模型技术的发布带火了非常多的向量数据库，特别是&lt;a href=&quot;https://python.langchain.com/docs/get_started/introduction&quot;&gt;LangChain&lt;/a&gt;、&lt;a href=&quot;https://docs.llamaindex.ai/en/stable/&quot;&gt;llama_index&lt;/a&gt;等LLM数据应用框架的发布，包括:&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Milvus&lt;/code&gt;、&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Qdrant&lt;/code&gt;、&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Pinecone&lt;/code&gt;、&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Chroma&lt;/code&gt;等等专业的向量数据库中间件。向量数据结构的存储与计算可以说是当前做大模型应用的基建产品了，就好像传统软件工程中的数据库一样。&lt;/p&gt;

&lt;p&gt;而对于ElasticSearch而言也同样如此，对于之前使用ElasticSearch中间件的开发人员而言，可能对于向量数据的存储和计算是比较陌生的，在传统软件工程用ES来储存搜索主要还是基于关键词搜索技术(BM25、TF-IDF)等实现，本质还是基于文本的精确匹配。而在最近ES组件发布的版本来看，特别是ES 8.0版本发布对于KNN算法搜索的优化支持来看，AI大模型这场技术革命风暴，似乎也不想袖手旁观。&lt;/p&gt;

&lt;p&gt;我们选择ElasticSearch作为TorchV的基础RAG架构组件也是出于以下几个方面考虑：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;开箱即用的语义搜索功能以及一流的相关性检索(BM25/TF-IDF)算法实现&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;区别于其它向量数据库所不具备的特有功能，包括：聚合、过滤、集群、分布式等等特性。&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;多年的技术沉淀和社区发展，不同编程语言的生态完善成熟度等&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;在ElasticSearch的目前的版本中，要使用向量实现存储和计算对于开发者使用上非常简单，开发者在定义ES的索引结构时，定义向量字段类型&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;dense_vector&lt;/code&gt;,并且自定义向量维度&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;dims&lt;/code&gt;(最大维度不超过4096(自8.x版本开始))，如下索引结构：&lt;/p&gt;

&lt;div class=&quot;language-json highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;err&quot;&gt;PUT&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;err&quot;&gt;test&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;-001&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;mappings&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;properties&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;my_vector&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;type&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;dense_vector&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;dims&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;  
      &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;my_text&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;type&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;keyword&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;在执行搜索时则可以通过&lt;a href=&quot;https://www.elastic.co/guide/en/elasticsearch/reference/8.0/knn-search.html&quot;&gt;k-最近邻(KNN)搜索&lt;/a&gt;找到与查询向量最近的K个向量结果值来获取结果，通过相似度值来衡量获取文档片段。&lt;/p&gt;

&lt;div class=&quot;language-json highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;err&quot;&gt;GET&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;err&quot;&gt;test&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;-001&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;/_knn_search&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;knn&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;field&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;my_vector&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;query_vector&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;k&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;num_candidates&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;_source&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;name&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;date&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;而我们在前面提到，&lt;strong&gt;混合检索&lt;/strong&gt;(语义搜索+相关性搜索)是目前做RAG的非常重要文档召回技术手段，纯KNN搜索并不能完全满足业务的需求，因此在当前的RAG技术架构体系中，ES在保持传统相关性搜索的基础上，增加对语义搜索的技术支持就显得很有冲击力，毕竟在向量搜索火爆之前，ES作为搜索引擎的老大哥，在企业级的产品应用体系中，应用范围还是非常广泛的。&lt;/p&gt;

&lt;h2 id=&quot;算法业务场景&quot;&gt;算法&amp;amp;业务场景&lt;/h2&gt;

&lt;p&gt;在做混合检索时，我们会接触到两类算法，需要对算法有一个基础了解，这有助于我们在应用产品的技术体系中做决策：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;语义检索：基于向量空间的KNN算法&lt;/li&gt;
  &lt;li&gt;相关性检索：传统的文本精确匹配方法，包括BM25、TF-IDF&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;语义检索knn&quot;&gt;语义检索(knn)&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm&quot;&gt;KNN算法&lt;/a&gt;&lt;/strong&gt;：k近邻算法，是机器学习算法中一种&lt;strong&gt;基本分类和回归方法&lt;/strong&gt;。在给定的一个数据集中，对于新的数据实例，找到与该实例最邻近的k个实例，这k个实例的多数属于某个分类。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;这就像你在一个陌生的城市，你可能会问周围的k个人哪家餐馆最好。如果大多数人都推荐同一家餐馆，那么你可能会选择去那家餐馆。&lt;/p&gt;

  &lt;p&gt;而我们在选择餐馆的过程中，每一个餐馆会有非常多的维度来描述这个餐馆的信息，包括：地理位置、菜系、价格、环境、口味等等，这一系列参数属性就是特征工程，目前的向量Embedding模型用来对一段文本进行Embedding，其实就是对于该文本内容的的特征信息进行提取描述。&lt;/p&gt;

  &lt;p&gt;这个时候，你会根据你自己的诉求，对于餐馆的不同特征要求，最终选择你要去哪家餐馆吃饭。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/rag/torchv/rag-2/KnnClassification.svg&quot; alt=&quot;图1-KNN算法图例&quot; /&gt;&lt;/p&gt;

&lt;p&gt;在Elasticsearch中，KNN搜索主要通过使用向量相似度(特征空间中的两个实例点间的距离可以反映出两点间的相似程度)进行度量，文档根据向量数据集与查询向量的相似度进行排名。每个文档的 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;_score&lt;/code&gt; 将从相似度中得出，以确保分数为正并且分数越高对应于越高的排名。&lt;/p&gt;

&lt;p&gt;ES目前主要提供了三种度量的标准供我们选择(考虑到本文是基于es，因此也只对该三种度量标准做介绍，对于其它的向量计算距离的方式，开发者可以自行搜索了解)&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;L2_norm&lt;/strong&gt;(欧式距离)：这是最常用的距离度量方式，它计算的是两个向量在笛卡尔坐标系中的直线距离。文档的&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;score&lt;/code&gt;计算方式为：&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;1 / (1 + l2_norm(query, vector)^2)&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;dot_product&lt;/strong&gt;(点积)：点积是两个向量的对应元素相乘然后求和，文档 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;_score&lt;/code&gt; 计算为 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;(1 + dot_product(query, vector)) / 2&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;cosine&lt;/strong&gt;(余弦相似度,&lt;strong&gt;default&lt;/strong&gt;)：计算两个向量余弦相似度，余弦相似性度量的是两个向量之间的角度，而不是距离。它的值范围是 -1 到 1，值越接近 1，表示两个向量越相似，文档 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;_score&lt;/code&gt; 计算为 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;(1 + cosine(query, vector)) / 2&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;我们在开发RAG的大模型应用产品中，通常会将外部的知识库通过chunk分段存储处理，对于用户的query，通过Embedding模型进行表征为向量后，与chunk片段的向量进行距离计算，此时作为距离度量的方式考虑，那么根据实际的业务场景，就可以考虑上面的三种类型中的一种。&lt;/p&gt;

&lt;p&gt;一般默认选择&lt;strong&gt;cosine余弦相似度&lt;/strong&gt;进行计算召回，主要考虑：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;长度不敏感&lt;/strong&gt;：在文本数据中，文档的长度可能会有很大的差异，这会影响到向量的长度。余弦相似性只关注向量的方向，而不关注长度，因此它对尺度不敏感，适合处理这种情况(虽然我们在使用向量Embedding模型进行表征时，向量的维度都是固定的)。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;方向敏感&lt;/strong&gt;：在问答系统中，我们通常关心的是文档的主题或者内容是否相似，而不是文档的长度。余弦相似性度量的是两个向量之间的角度，可以很好地反映出文档的主题或者内容是否相似。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;高维数据&lt;/strong&gt;：向量Embedding模型表征的高维度(768/1024/1536…等等)向量，适合余弦相似性适合处理这种高维稀疏的数据。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;而ES自8.0版本发布后，同样也提供了对&lt;a href=&quot;https://www.elastic.co/guide/en/elasticsearch/reference/current/knn-search.html&quot;&gt;KNN搜索&lt;/a&gt;的优化，主要提供了两种策略：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;近邻KNN搜索算法(&lt;strong&gt;ANN&lt;/strong&gt;)：数据结构基于&lt;a href=&quot;https://www.luxiangdong.com/2023/11/06/hnsw/&quot;&gt;HNSW算法&lt;/a&gt;索引实现，近似 kNN 提供较低的延迟，但代价是索引速度较慢且准确性不完善(这也为后来RAG架构中的文档检索结果做ReRank重排埋下伏笔，可以关注员外的这篇&lt;a href=&quot;https://mp.weixin.qq.com/s/4UoRi8VhQjfE7zcpFnre4A&quot;&gt;《Rerank——RAG中百尺竿头更进一步的神器，从原理到解决方案》&lt;/a&gt;)。&lt;/li&gt;
  &lt;li&gt;精确、强力的 kNN搜索(&lt;strong&gt;暴力搜索&lt;/strong&gt;)：基于函数实现，这种方式能够保证结果的准确性，通过计算&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;script_score&lt;/code&gt; 函数扫描每个匹配文档计算向量距离获取文档结果集，这会导致搜索速度缓慢(大数据集的应用场景下)。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;开发者在选择KNN搜索的算法策略时，可以根据自己的实际业务需要进行抉择。&lt;/p&gt;

&lt;h3 id=&quot;相关性检索bm25tf-idf&quot;&gt;相关性检索(BM25/TF-IDF)&lt;/h3&gt;

&lt;p&gt;ES自5.0版本之后，针对文档的相关性评分机制默认采用了BM25相似度算法(之前是基于TF-IDF)，BM25全称&lt;a href=&quot;https://en.wikipedia.org/wiki/Okapi_BM25&quot;&gt;Okapi BM25&lt;/a&gt;。Okapi 是使用它的第一个系统的名称，即Okapi信息检索系统,于 20 世纪 80 年代和 1990 年代在伦敦城市大学实施。 BM则是best matching的缩写。&lt;/p&gt;

&lt;p&gt;因此对于词的相关性检索方案，我们对于TF-IDF和BM25也需要有一个基础的了解。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;TF-IDF(Term Frequency-Inverse Document Frequency)&lt;/strong&gt;:词频-逆文档频率是一个常用于信息检索和文本挖掘的权重计算方法，函数公式如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/rag/torchv/rag-2/tf_idf.png&quot; alt=&quot;tf-idf&quot; /&gt;&lt;/p&gt;

&lt;p&gt;主要由两部分组成：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;TF（Term Frequency，词频）&lt;/strong&gt;：衡量一个词在文档中出现的频率。假设某一词条在文本中出现的次数为&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;n&lt;/code&gt;，文本的总词条数为&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;m&lt;/code&gt;，则词频TF为n/m,也就是词频，比如一个单词:&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;旅游&lt;/code&gt;在我们的一篇文档中出现了4次，而我们的文档总共包含的词条数量是100，那么词频的值就是&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;4/100&lt;/code&gt;。词频越高，说明这个词在文档中越重要。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;IDF（Inverse Document Frequency，逆文档频率）&lt;/strong&gt;：衡量一个词是否常见的度量。如果某个词在很多文档中都出现，那么它可能就不具有区分能力(比如常用词等)。它的计算公式是：log(文档总数(N) / 包含该词的文档数(df))。逆文档频率越大，说明这个词越不常见，可能就越重要。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;TF-IDF就是将这两个值相乘，得到的结果就是一个词的权重，这个权重可以用来表示这个词对于文档的重要性，也可以用来比较不同文档的相似性。&lt;/p&gt;

&lt;p&gt;TF-IDF在实践的发展中会存在一些问题:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;文档长度问题：在长文档中，某个词可能会因为文档本身的长度就有更高的出现次数，而不是因为这个词对于文档的主题更重要。这可能会导致TF-IDF对长文档中的词给予过高的权重，而忽视了短文档中的重要词&lt;/li&gt;
  &lt;li&gt;词频不饱和：在实际的业务场景中，词的重要性并不总是随着它的出现次数线性增加的。例如，一个词在文档中出现100次可能并不意味着它比出现10次的词10倍重要，相反，对于IDF而言，如果一个词在文档集中出现的次数越少，那么它的IDF值就越高，被认为越重要,也并非一定符合实际业务场景。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;这些问题都在BM25中得到了改进，BM25的词频部分使用了一个饱和函数，使得词频达到一定值后，增加词频对于最终得分的影响会变小。同时，BM25还考虑了文档长度的影响，通过一个归一化因子来调整不同长度文档中的词频。这使得BM25在处理词频未饱和和文档长度问题时，比TF-IDF有更好的性能。&lt;/p&gt;

&lt;p&gt;BM25 的计算公式：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/rag/torchv/rag-2/bm25.png&quot; alt=&quot;BM25&quot; /&gt;&lt;/p&gt;

&lt;p&gt;和TF-IDF的计算公式相比，BM25的公式着实有点吓人，不过其实我们关注几个核心的参数即可。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;对于BM25算法在ElasticSearch中的应用公式和参数变量说明，可以参考这篇文章&lt;a href=&quot;https://www.elastic.co/cn/blog/practical-bm25-part-2-the-bm25-algorithm-and-its-variables&quot;&gt;《BM25 算法及其变量》&lt;/a&gt;，这里我们只关心几个核心的参数&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;k1&lt;/strong&gt;:控制非线性项频率归一化（词频饱和度）。默认值为 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;1.2&lt;/code&gt; 。较低的值导致较快的饱和，较高的值导致较慢的饱和。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/rag/torchv/rag-2/elas_1706.png&quot; alt=&quot;Term frequency saturation for TF/IDF and BM25&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;b&lt;/strong&gt;：该参数控制字段长度归一化的影响程度。b的值在0到1之间，当b为0时，表示完全不考虑字段长度的影响；当b为1时，表示完全考虑字段长度的影响。默认为 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;0.75&lt;/code&gt; 。这个参数值也是针对上面我们提到TF-IDF在文档长度未考虑的情况下一个加权计算，当然默认值&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;0.75&lt;/code&gt;是官方基于大量的数据实验得到的一个值，在默认场景下都会有较好的效果，我们可以不用调整。如果我们的默认检索效果不佳，应该从其它方面来考虑优化，这个后面我们再说&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;score分值计算注意事项&quot;&gt;Score分值计算&amp;amp;注意事项&lt;/h2&gt;

&lt;blockquote&gt;
  &lt;p&gt;在理解了算法、es中间件之后，结合实战+Score分值的计算使用过程，包括配合ES的Explain接口，讲清楚Score的计算规则，原理&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;在前面了解了ES的整个检索Score算法介绍之后，其实对于文本内容的检索召回Score分值计算，就比较清晰了，先说结论：&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;ElasticSearch在使用KNN+BM25检索的混合检索分值Score计算公式是：knn_score+bm25_score&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;使用ES混合检索的语法如下：&lt;/p&gt;

&lt;div class=&quot;language-json highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;err&quot;&gt;POST&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;err&quot;&gt;image-index/_search&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;query&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;match&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;title&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;query&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;mountain lake&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;boost&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.9&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;knn&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;err&quot;&gt;//&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;err&quot;&gt;字段&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;field&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;image-vector&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;err&quot;&gt;//&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;err&quot;&gt;输入向量&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;query_vector&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;54&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;-2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;err&quot;&gt;//&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;err&quot;&gt;k值&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;k&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;err&quot;&gt;//&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;err&quot;&gt;每个分片要考虑的最近邻居候选数。不能超过&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;000&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;num_candidates&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;err&quot;&gt;//&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;err&quot;&gt;加权参数值&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;boost&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;err&quot;&gt;//&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;err&quot;&gt;档被视为匹配所需的最小相似度&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;配合filter使用，提高检索效率&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;similarity&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;err&quot;&gt;//&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;err&quot;&gt;过滤条件&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;filter&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;term&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;file-type&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;png&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;size&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;query&lt;/code&gt;部分的检索所代表的是BM25算法的Score计算分值召回，而&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;knn&lt;/code&gt;部分的检索所代表的则是语义向量空间的距离Score分值，最终的结果值相加后倒排的一个文档列表结果集&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;score=&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;match_score*0.9 + knn_score*0.1&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;bm25的score&quot;&gt;BM25的Score&lt;/h3&gt;

&lt;p&gt;对于BM25算法的检索分值计算，开发者可以使用&lt;a href=&quot;https://www.elastic.co/guide/en/elasticsearch/reference/8.11/search-explain.html&quot;&gt;Explain API&lt;/a&gt;来查看整个&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Score&lt;/code&gt;的计算过程，整个计算过程就和BM25算法公式那样,如下图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/rag/torchv/rag-2/image-20231227182031006.png&quot; alt=&quot;图2-BM25算法score解释接口&quot; /&gt;&lt;/p&gt;

&lt;p&gt;BM25算法会将用户输入的match参数，计算每一个分词的score分值，最终加起来，得到一个总的分值score数据，对于每一个分词，都可以通过该接口查看到完整的计算过程，是非常方便的开发者进行理解的。&lt;/p&gt;

&lt;p&gt;在这里进行BM25计算时，我前面提到BM25算法可能存在检索不到最终我们说期望的文本，会有一些其它参数影响最终效果，并非需要更改算法中的k1和b这两个参数，主要考虑如下：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;ES是一个分布式搜索和分析引擎，数据被分为多个分片（shards），每个分片可以在任何节点上存储。这使得数据可以在多个节点之间进行分布，从而提高系统的容量和性能，最终数据在存储构建索引的时候，es会均衡的进行分布存储，而在召回计算的过程中，数据也会从各个shards分片进行召回计算。开发者在创建索引(index)的时候，可以设置shards的分片为1或者3，来查看区别。&lt;/li&gt;
  &lt;li&gt;es默认提供了非常多的tokenizer分词器，而对于中文用户的使用者来说，哪些词该分，哪些词不该分，包括同义词的影响等等，都会影响整个Score分值的计算，在目前es的生态中，&lt;a href=&quot;https://github.com/medcl/elasticsearch-analysis-ik&quot;&gt;ik分词器&lt;/a&gt;可能是当下最成熟的一个plugin插件，ik提供了一个基础的词库，同时支持热更新，对于上层应用产品的设计融合，非常刚需。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;knn的score&quot;&gt;KNN的Score&lt;/h3&gt;

&lt;p&gt;对于KNN的检索分值计算，就非常的简单了，开发者在构建用户索引的时候，选择具体的向量距离类型，es在计算knn的时候，就会根据其算法进行计算&lt;/p&gt;

&lt;div class=&quot;language-json highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;err&quot;&gt;PUT&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;err&quot;&gt;my-index&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;-2&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;mappings&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;properties&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;my_vector&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;type&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;dense_vector&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;dims&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1024&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;err&quot;&gt;//&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;err&quot;&gt;选择类型，cosine、dot_product、l&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;_norm&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;similarity&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;cosine&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;选择不同的类型， 就是单纯的向量距离计算了，按公式套用就可以了。&lt;/p&gt;

&lt;p&gt;不过值得注意的是，对于使用最多的&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;cosine&lt;/code&gt;的文档 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;_score&lt;/code&gt; 计算为 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;(1 + cosine(query, vector)) / 2&lt;/code&gt;。&lt;/p&gt;

&lt;h3 id=&quot;️注意事项&quot;&gt;⚠️注意事项&lt;/h3&gt;

&lt;p&gt;当我们使用混合检索的时候，有一些注意事项值得我们关注：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;开发者在使用Explain API接口进行调试的时候，由于KNN的分值是单独计算，所以在分析的时候，不能有KNN的部分&lt;/li&gt;
  &lt;li&gt;KNN检索的参数，可以配置多个knn的向量查询值，另外&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;filter&lt;/code&gt;过滤参数会提高检索的效率，但是提高检索效率的同时，由于总是会计算召回文档进行相似度计算，所以可以配合&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;similarity&lt;/code&gt;来一起使用。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;torchv产品驱动总结&quot;&gt;TorchV产品驱动&amp;amp;总结&lt;/h2&gt;

&lt;p&gt;对于混合检索，我们在算法层面有了直接的了解后，最终在产品层面会影响一些设计。&lt;/p&gt;

&lt;p&gt;1、混合检索的权重设置：在上面的score分值计算公式中，我们其实知道es最终是通过&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;bm25*boost&lt;/code&gt;+&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;knn*boost&lt;/code&gt;,那么这个&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;boost&lt;/code&gt;则可以影响我们最终的内容，因为并不是所有的客户和业务场景都适合knn检索，可能在其他关键的场景中，关键词检索会更适合(比如一些利用大模型做一些异步的任务提取，报告输出等等业务场景)，我们在产品设计中则可以根据不同的客户诉求以及业务诉求，就可以设置这个&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;boost&lt;/code&gt;来影响最终的召回结果天平，从而改善我们的产品效果。&lt;/p&gt;

&lt;p&gt;在我们的TorchV的产品设计中，我们设计了一个&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;alpha&lt;/code&gt;参数值，取值范围在0-1之间，具体来说：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;alpha = 1&lt;/code&gt;：完全基于向量的搜索,也就是KNN近邻搜索&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;alpha = 0&lt;/code&gt;：完全基于关键词的搜索，基于ES的BM25算法检索&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;2、在BM25算法的场景中，分词是非常重要的一个特性，对于不同的行业客户，词库的收集建立对于产品应用的提升肯定是会有质的提升，也是每个公司做RAG产品的核心竞争力。&lt;/p&gt;

&lt;p&gt;3、持续运营能力的重要性，RAG问答检索功能在技术架构迭代优化上是一个方面，但是运营能力同样重要，哪怕是ChatGPT4，在针对特殊的数据文件，如果数据混乱，知识库质量不高，那么同样回答准确率不会很好的，这在我们和客户进行沟通交流的同时，虽然RAG可能会给客户眼前一亮的感觉，但是持续的提升他的能力，发挥更大的作用，产品的持续运营能力是必不可少的。&lt;/p&gt;

&lt;h2 id=&quot;参考&quot;&gt;参考&lt;/h2&gt;

&lt;p&gt;好了，全文完.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://weaviate.io/blog/hybrid-search-explained&quot;&gt;https://weaviate.io/blog/hybrid-search-explained&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Okapi_BM25&quot;&gt;https://en.wikipedia.org/wiki/Okapi_BM25&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1603.09320&quot;&gt;https://arxiv.org/abs/1603.09320&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.elastic.co/guide/en/elasticsearch/reference/7.17/query-dsl-script-score-query.html#vector-functions&quot;&gt;https://www.elastic.co/guide/en/elasticsearch/reference/7.17/query-dsl-script-score-query.html#vector-functions&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://towardsdatascience.com/improving-retrieval-performance-in-rag-pipelines-with-hybrid-search-c75203c2f2f5&quot;&gt;https://towardsdatascience.com/improving-retrieval-performance-in-rag-pipelines-with-hybrid-search-c75203c2f2f5&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.luxiangdong.com/2023/11/06/hnsw/&quot;&gt;https://www.luxiangdong.com/2023/11/06/hnsw/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>八一菜刀</name></author><category term="大模型" /><category term="RAG实践" /><category term="TorchV" /><category term="RAG概述" /><category term="RAG" /><category term="大模型" /><category term="LLM" /><summary type="html">概述</summary></entry><entry><title type="html">RAG的概述</title><link href="http://localhost:4000/2023/12/23/rag-survey/" rel="alternate" type="text/html" title="RAG的概述" /><published>2023-12-23T00:00:00+08:00</published><updated>2023-12-23T00:00:00+08:00</updated><id>http://localhost:4000/2023/12/23/rag-survey</id><content type="html" xml:base="http://localhost:4000/2023/12/23/rag-survey/">&lt;p&gt;待续…&lt;/p&gt;</content><author><name>八一菜刀</name></author><category term="大模型" /><category term="RAG概述" /><category term="RAG" /><category term="大模型" /><category term="LLM" /><summary type="html">待续…</summary></entry><entry><title type="html">基于Apple MLX框架的M1设备上大模型微调实践</title><link href="http://localhost:4000/2023/12/17/apple-mlx-lora-action/" rel="alternate" type="text/html" title="基于Apple MLX框架的M1设备上大模型微调实践" /><published>2023-12-17T00:00:00+08:00</published><updated>2023-12-17T00:00:00+08:00</updated><id>http://localhost:4000/2023/12/17/apple-mlx-lora-action</id><content type="html" xml:base="http://localhost:4000/2023/12/17/apple-mlx-lora-action/">&lt;h2 id=&quot;前言&quot;&gt;前言&lt;/h2&gt;

&lt;p&gt;在不久前苹果官方开源发布了针对Apple Silicon 芯片优化的 MLX 深度学习框架，该框架可以简化研究人员在 Mac、iPad、iPhone 平台设计和部署模型的过程。&lt;/p&gt;

&lt;p&gt;MLX的主要特性包括：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;熟悉的API&lt;/strong&gt;：&lt;strong&gt;MLX&lt;/strong&gt; 具有紧随 NumPy 的 Python API。 MLX 还拥有功能齐全的 C++ API，它与 Python API 非常相似。 MLX 具有 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;mlx.nn&lt;/code&gt; 和 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;mlx.optimizers&lt;/code&gt; 等更高级别的包，其 API 紧密遵循 PyTorch，以简化构建更复杂的模型。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;可组合函数转换&lt;/strong&gt;：MLX 具有用于自动微分、自动矢量化和计算图优化的可组合函数转换&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;惰性计算 (Lazy computation)&lt;/strong&gt;：MLX 中的计算是惰性计算。数组仅在需要时才会具体化&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;动态图构建&lt;/strong&gt;：MLX 中的计算图采用动态构建，更改函数参数的形状不会触发缓慢的编译，并且调试简单直观&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;多设备：&lt;/strong&gt;可以在任何支持的设备上运行（当前为 CPU 和 GPU），确保用户能够充分利用硬件&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;具备统一内存优势&lt;/strong&gt;：MLX 和其他框架的显着区别是采用统一内存模型。 MLX 中的数组位于共享内存中，可以在任何支持的设备类型上执行 MLX 阵列上的操作，而无需移动数据。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;项目地址：&lt;a href=&quot;https://github.com/ml-explore/mlx&quot;&gt;https://github.com/ml-explore/mlx&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;而在今天的X上看到Apple开发者分享说可以在32GB的M1设备上使用MLX框架对Mistral 7B(或者llamA)等模型进行微调(Fine-tune)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/llm/apple-mlx-lora-action/image-20231216193342777.png&quot; alt=&quot;image-20231216193342777&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;准备&quot;&gt;准备&lt;/h2&gt;

&lt;p&gt;看到官方的例子，我的电脑正好是M1 32GB的配置，就把代码跑来试试看&lt;/p&gt;

&lt;p&gt;首先代码下载下来，地址：&lt;a href=&quot;https://github.com/ml-explore/mlx-examples/tree/main/lora&quot;&gt;https://github.com/ml-explore/mlx-examples/tree/main/lora&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;安装依赖：&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;pip &lt;span class=&quot;nb&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-r&lt;/span&gt; requirements.txt
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;下载Mistral-7B(14.48GB大小)的模型并解压&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;curl &lt;span class=&quot;nt&quot;&gt;-O&lt;/span&gt; https://files.mistral-7b-v0-1.mistral.ai/mistral-7B-v0.1.tar
&lt;span class=&quot;nb&quot;&gt;tar&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-xf&lt;/span&gt; mistral-7B-v0.1.tar
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;将下载下来的模型文件进行转换，执行&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;convert.py&lt;/code&gt;文件, 命令如下：&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# 转换命令&lt;/span&gt;
python convert.py &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;--torch-model&lt;/span&gt; &amp;lt;path_to_torch_model&amp;gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;--mlx-model&lt;/span&gt; &amp;lt;path_to_mlx_model&amp;gt;
&lt;span class=&quot;c&quot;&gt;# 转换&lt;/span&gt;
python convert.py &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--torch-model&lt;/span&gt; mistral-7B-v0.1 &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--mlx-model&lt;/span&gt; mistral-7b-v0.1-mlx
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;两个主要的参数:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;torch-model: Mistral模型的目录，解压后为当前的&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;mistral-7B-v0.1&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;mlx-model: 输出目录名称，这里取名&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;mistral-7b-v0.1-mlx&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;通过命令转换后，转换的目录文件会有三个文件，如下图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/llm/apple-mlx-lora-action/image-20231216201202978.png&quot; alt=&quot;image-20231216201202978&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;微调fine-tune&quot;&gt;微调(Fine-tune)&lt;/h2&gt;

&lt;p&gt;将模型下载转换完成后，接下来就可以使用官方提供的&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;lora.py&lt;/code&gt;进行微调(&lt;strong&gt;Fine-tune&lt;/strong&gt;)了，先来看数据集：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/llm/apple-mlx-lora-action/image-20231216194706972.png&quot; alt=&quot;image-20231216194706972&quot; /&gt;&lt;/p&gt;

&lt;p&gt;训练的数据集是1000行，主要的格式：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;微调目标是得到一个能够将自然语言句子转换为SQL&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div class=&quot;language-json highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;&quot;text&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;table: 1-1000181-1&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;columns: State/territory, Text/background colour, Format, Current slogan, Current series, Notes&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;Q: Tell me what the notes are for South Australia &lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;A: SELECT Notes FROM 1-1000181-1 WHERE Current slogan = 'SOUTH AUSTRALIA'&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;数据集的格式很清晰：&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;table: 表名称
columns: 列名称
Q: 用户问题
A: SQL语句
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;训练&quot;&gt;训练&lt;/h2&gt;

&lt;p&gt;在第一次train的过程中，直接使用demo中的命令：&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;python lora.py &lt;span class=&quot;nt&quot;&gt;--model&lt;/span&gt; &amp;lt;path_to_model&amp;gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
               &lt;span class=&quot;nt&quot;&gt;--train&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
               &lt;span class=&quot;nt&quot;&gt;--iters&lt;/span&gt; 600
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;运行了大概10分钟后，程序就异常退出了，提示内存不足。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/llm/apple-mlx-lora-action/image-20231216195734079.png&quot; alt=&quot;image-20231216195734079&quot; /&gt;&lt;/p&gt;

&lt;p&gt;从图中可以看出，在声明内存的过程中，出现了异常，无法开辟新内存空间，并且每秒的Tokens数量也很感人😭&lt;/p&gt;

&lt;p&gt;在看了官方的针对内存的issues建议后，发现有几个参数是影响着内存使用的：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;–batch-size&lt;/strong&gt;：尝试通过 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;--batch-size&lt;/code&gt; 使用较小的批量大小。 默认值为 4，因此将其设置为 2 或 1 将减少内存消耗。 这可能会减慢速度，但也会减少内存使用。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;–lora-layers&lt;/strong&gt;:少层数以使用 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;--lora-layers&lt;/code&gt; 进行微调。 默认值为 16，因此您可以尝试 8 或 4。这会减少反向传播所需的内存量。 如果您使用大量数据进行微调，它还可能会降低微调模型的质量。&lt;/li&gt;
  &lt;li&gt;数据集：较长的示例需要更多的内存。 如果这对您的数据有意义，您可以做的一件事是在制作 {train, valid, test}.jsonl 文件时将示例分解为更小的序列。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;根据官方的建议，那么修改train参数，如下：&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;python lora.py &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;--model&lt;/span&gt; mistral-7b-v0.1-mlx &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;--train&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;--batch-size&lt;/span&gt; 1 &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;--lora-layers&lt;/span&gt; 4
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;按这个命令执行后，在我的M1设备上执行的还比较快，每秒的Tokens数量平均上110左右&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/llm/apple-mlx-lora-action/image-20231216200532260.png&quot; alt=&quot;image-20231216200532260&quot; /&gt;&lt;/p&gt;

&lt;p&gt;而Loss的值如下：&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Iter&lt;/th&gt;
      &lt;th&gt;Loss&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;2.265&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;200&lt;/td&gt;
      &lt;td&gt;1.516&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;400&lt;/td&gt;
      &lt;td&gt;1.380&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;600&lt;/td&gt;
      &lt;td&gt;1.350&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;800&lt;/td&gt;
      &lt;td&gt;1.325&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;train完成后，会在本地默认生成一个权重文件&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;adapters.npz&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;测试结果：&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;python lora.py &lt;span class=&quot;nt&quot;&gt;--model&lt;/span&gt; mistral-7b-v0.1-mlx &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
               &lt;span class=&quot;nt&quot;&gt;--adapter-file&lt;/span&gt; adapters.npz &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
               &lt;span class=&quot;nt&quot;&gt;--num-tokens&lt;/span&gt; 50 &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
               &lt;span class=&quot;nt&quot;&gt;--prompt&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;table: 1-10015132-16
columns: Player, No., Nationality, Position, Years in Toronto, School/Club Team
Q: What is terrence ross' nationality
A: &quot;&lt;/span&gt;
Loading pretrained model
Total parameters 7243.436M
Trainable parameters 1.704M
Loading datasets
Generating
table: 1-10015132-16
columns: Player, No., Nationality, Position, Years &lt;span class=&quot;k&quot;&gt;in &lt;/span&gt;Toronto, School/Club Team
Q: What is terrence ross&lt;span class=&quot;s1&quot;&gt;' nationality
# 大模型输出
A:  SELECT Nationality FROM 1-10015132-16 WHERE Player = '&lt;/span&gt;Terrence Ross&lt;span class=&quot;s1&quot;&gt;' blowing off the rosshill. SELECT Nationality FROM 1-10015
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;从结果看，SQL的前半部分写对了，并且也识别出了字段、where条件，但是后面的句子好像就不太对了&lt;/p&gt;

&lt;p&gt;我怀疑是在train时，参数&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;--lora-layers 4&lt;/code&gt;的问题，这时，我将改参数改为8，在train一次&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;python lora.py &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;--model&lt;/span&gt; mistral-7b-v0.1-mlx &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;--train&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;--adapter-file&lt;/span&gt; adapters_2_8_1.npz &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;--batch-size&lt;/span&gt; 2 &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;--lora-layers&lt;/span&gt; 8
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;而Loss的值如下：&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Iter&lt;/th&gt;
      &lt;th&gt;loss&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;2.348&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;200&lt;/td&gt;
      &lt;td&gt;1.392&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;400&lt;/td&gt;
      &lt;td&gt;1.293&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;800&lt;/td&gt;
      &lt;td&gt;1.213&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;1000&lt;/td&gt;
      &lt;td&gt;1.233&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;之后，同样的命令，再来看效果：&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;python lora.py &lt;span class=&quot;nt&quot;&gt;--model&lt;/span&gt; mistral-7b-v0.1-mlx &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
               &lt;span class=&quot;nt&quot;&gt;--adapter-file&lt;/span&gt; adapters_2_8.npz &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
               &lt;span class=&quot;nt&quot;&gt;--num-tokens&lt;/span&gt; 50 &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
               &lt;span class=&quot;nt&quot;&gt;--prompt&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;table: 1-10015132-16
columns: Player, No., Nationality, Position, Years in Toronto, School/Club Team
Q: What is terrence ross' nationality
A: &quot;&lt;/span&gt;
Loading pretrained model
Total parameters 7243.436M
Trainable parameters 1.704M
Loading datasets
Generating
table: 1-10015132-16
columns: Player, No., Nationality, Position, Years &lt;span class=&quot;k&quot;&gt;in &lt;/span&gt;Toronto, School/Club Team
Q: What is terrence ross&lt;span class=&quot;s1&quot;&gt;' nationality
A:  SELECT Nationality FROM 1-10015132-16 WHERE Player = '&lt;/span&gt;Terrence Ross&lt;span class=&quot;s1&quot;&gt;' SELECT Nationality FROM 1-10015132-16 WHERE
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;看效果好像在SQL语句中，比上面的效果稍微要好一点了?但是结果还是不对。&lt;/p&gt;

&lt;p&gt;效果并没有达到预期，我觉得主要是可能有几个方面的原因：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;训练数据集太少，导致大模型可能无法,train.jsonl中的数据集是1000&lt;/li&gt;
  &lt;li&gt;参数&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;--lora-layers &lt;/code&gt;的问题，默认是16，虽然我最后改成了8，但是从官方给出的说明来看，该参数会影响质量&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;我将参数&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;--lora-layers &lt;/code&gt;修改为16进行了尝试，跑不了，可能还是我的内存太低了😭，那我只能加数据集了&lt;/p&gt;

&lt;p&gt;修改了data目录下的wikisql.py文件，将数据集下载整理的总体数量上升到10000，代码：&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;__name__&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;__main__&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;datanames&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;train&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;dev&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;test&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;sizes&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;56355&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;8421&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;15878&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dataname&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;zip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;datanames&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sizes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;WikiSQL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dataname&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Wrong &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dataname&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; set size.&quot;&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Write the sets to jsonl
&lt;/span&gt;    &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;json&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dev&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;load&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# 此处原train参数是1000，我改成5000
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;datasets&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;train&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dev&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;valid&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;test&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;datasets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;open&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;data/&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;.jsonl&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;w&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;zip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
                &lt;span class=&quot;c1&quot;&gt;# Strip the &amp;lt;s&amp;gt;, &amp;lt;/s&amp;gt; since the tokenizer adds them
&lt;/span&gt;                &lt;span class=&quot;n&quot;&gt;json&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dump&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;({&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;text&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]},&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;fid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;write&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;修改数据集后，在train过后，得到一个新的权重文件，命令：&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;python lora.py &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;--model&lt;/span&gt; mistral-7b-v0.1-mlx &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;--train&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;--adapter-file&lt;/span&gt; adapters_2_8_1.npz &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;--batch-size&lt;/span&gt; 2 &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;--lora-layers&lt;/span&gt; 8
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;loss的train过程分值变化：&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Iter&lt;/th&gt;
      &lt;th&gt;loss&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;2.348&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;200&lt;/td&gt;
      &lt;td&gt;1.472&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;400&lt;/td&gt;
      &lt;td&gt;1.410&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;600&lt;/td&gt;
      &lt;td&gt;1.387&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;800&lt;/td&gt;
      &lt;td&gt;1.360&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;1000&lt;/td&gt;
      &lt;td&gt;1.349&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;再来看看我们的promt得到的结果：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/llm/apple-mlx-lora-action/image-20231217105402278.png&quot; alt=&quot;image-20231217105402278&quot; /&gt;&lt;/p&gt;

&lt;p&gt;从结果来看，SQL语句的语法好像并没有什么大的问题，只是结果没有达到预期，可能还是得从数据集及相关参数找一下原因。&lt;/p&gt;

&lt;h2 id=&quot;结论&quot;&gt;结论&lt;/h2&gt;

&lt;p&gt;虽然运行的结果还没有完全达到预期，但是在MAC上通过Apple推出的MLX深度学习框架进行Fine-ture的技术方案是可行的。&lt;/p&gt;

&lt;p&gt;这也为以后大模型的训练、生态发展提供了另外一种可能性。&lt;/p&gt;

&lt;p&gt;包括我们应用开发者在做RAG的过程中，和数据进行对话的场景随着业务的深入肯定会触及，而对模型进行微调是不可避免的。&lt;/p&gt;

&lt;h2 id=&quot;reference&quot;&gt;Reference&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/ml-explore/mlx-examples/tree/main/lora&quot;&gt;https://github.com/ml-explore/mlx-examples/tree/main/lora&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/ml-explore/mlx&quot;&gt;https://github.com/ml-explore/mlx&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://twitter.com/awnihannun/status/1735782998623261071&quot;&gt;https://twitter.com/awnihannun/status/1735782998623261071&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>八一菜刀</name></author><category term="大模型" /><summary type="html">前言</summary></entry><entry><title type="html">Python3.11在CentOS7环境下的安装指定OpenSSL</title><link href="http://localhost:4000/2023/11/07/centos-python311-install/" rel="alternate" type="text/html" title="Python3.11在CentOS7环境下的安装指定OpenSSL" /><published>2023-11-07T00:00:00+08:00</published><updated>2023-11-07T00:00:00+08:00</updated><id>http://localhost:4000/2023/11/07/centos-python311-install</id><content type="html" xml:base="http://localhost:4000/2023/11/07/centos-python311-install/">&lt;p&gt;如果你是在CentOS7 上面源码安装Python3.11版本，你可能会碰到和我一样的问题，那就是OpenSSL模块太低了。&lt;/p&gt;

&lt;p&gt;在源码编译安装时，如果没有指定OpenSSL那么在使用时会出现一些异常，解决方案：&lt;/p&gt;

&lt;p&gt;1、更新yum软件包&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;yum update
yum &lt;span class=&quot;nb&quot;&gt;install &lt;/span&gt;openssl-devel bzip2-devel libffi-devel
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;2、下载最新的OpenSSL源码，解压并编译&lt;/p&gt;

&lt;div class=&quot;language-py highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;cd&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;usr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;src&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;wget&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;https&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;//&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ftp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;openssl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;org&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;source&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;openssl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;q&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tar&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gz&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;--&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;no&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;check&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;certificate&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;解压OpenSSL包并安装&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# 解压&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;tar&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-xzvf&lt;/span&gt; openssl-1.1.1q.tar.gz
&lt;span class=&quot;nb&quot;&gt;cd &lt;/span&gt;openssl-1.1.1q
&lt;span class=&quot;c&quot;&gt;# 编译&lt;/span&gt;
./config &lt;span class=&quot;nt&quot;&gt;--prefix&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;/usr &lt;span class=&quot;nt&quot;&gt;--openssldir&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;/etc/ssl &lt;span class=&quot;nt&quot;&gt;--libdir&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;lib no-shared zlib-dynamic
make
&lt;span class=&quot;c&quot;&gt;# 安装&lt;/span&gt;
make &lt;span class=&quot;nb&quot;&gt;install&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;3、验证版本&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; openssl version
OpenSSL 1.1.1q  5 Jul 2022
&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; which openssl
/usr/bin/openssl
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;4、下载Python的源码包，解压并安装&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;## 解压&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;tar&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-xzf&lt;/span&gt; Python-3.11.6.tgz
&lt;span class=&quot;nb&quot;&gt;cd &lt;/span&gt;Python-3.11.6
&lt;span class=&quot;c&quot;&gt;# 编译（指定python3的目录和openssl模块）&lt;/span&gt;
./configure &lt;span class=&quot;nt&quot;&gt;--prefix&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;/mnt/python/python3 &lt;span class=&quot;nt&quot;&gt;--with-openssl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;/usr
&lt;span class=&quot;c&quot;&gt;# 安装&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;make
&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;make &lt;span class=&quot;nb&quot;&gt;install&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;5、生成软链&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;系统中可能已经存在python3的命令，删除重新命名即可&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;在上面我们指定安装目录在&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/mnt/python/python3&lt;/code&gt;下,所以可以直接创建软链&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;sudo ln&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-s&lt;/span&gt; /mnt/python/python3/bin/python3.11 /usr/bin/python3
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://stackoverflow.com/questions/73407527/installing-ssl-package-with-pip-requires-ssl-package-to-be-already-installed&quot;&gt;Installing SSL package with PIP requires SSL package to be already installed&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>八一菜刀</name></author><category term="Blog" /><category term="Python" /><summary type="html">如果你是在CentOS7 上面源码安装Python3.11版本，你可能会碰到和我一样的问题，那就是OpenSSL模块太低了。</summary></entry><entry><title type="html">超赞的博客主题分享，值得一看</title><link href="http://localhost:4000/2023/10/16/jekyll-theme-chirpy-share/" rel="alternate" type="text/html" title="超赞的博客主题分享，值得一看" /><published>2023-10-16T00:00:00+08:00</published><updated>2023-10-16T00:00:00+08:00</updated><id>http://localhost:4000/2023/10/16/jekyll-theme-chirpy-share</id><content type="html" xml:base="http://localhost:4000/2023/10/16/jekyll-theme-chirpy-share/">&lt;p&gt;最近在学习RAG、&lt;a href=&quot;/categories/大模型/&quot;&gt;大模型&lt;/a&gt;等领域方面的技术，想在学习的过程中做总结性的输出，因此就想把自己之前弄的博客重新整理一番,主要有几个原因:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;博客网页无法适配移动端(非常重要的一个特性)&lt;/li&gt;
  &lt;li&gt;主题有些腻了,想换个新主题&lt;/li&gt;
  &lt;li&gt;GitHub Pages &amp;lt;-&amp;gt; 博客 &amp;lt;-&amp;gt; 微信公众号 整体链路的文章编写发布顺畅的诉求&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;后来，就基于自己的想法，整理的了要重新整理博客的需求，列了一个思维导图，如下图:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/blog2/jekyll-theme-share/blog_build.png&quot; alt=&quot;图1-博客需求整理&quot; /&gt;&lt;/p&gt;

&lt;p&gt;主要从以下几个方面考虑：&lt;/p&gt;

&lt;h2 id=&quot;1基础框架&quot;&gt;1.基础框架&lt;/h2&gt;

&lt;p&gt;肯定是基于目前已经开放流行的博客框架进行改造,这样能够快速的搭建完成,而且无需考虑页面布局的情况&lt;/p&gt;

&lt;p&gt;这里列的大部分我都是用过&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://vuepress.vuejs.org/zh/guide/&quot;&gt;VuePress&lt;/a&gt;: Vue 驱动的静态网站生成器,在很早给&lt;a href=&quot;https://doc.xiaominfo.com/v2/&quot;&gt;Knife4j&lt;/a&gt;写开源的技术文档时就使用的这个&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://vitepress.dev/&quot;&gt;VitePress&lt;/a&gt;: 在Vite框架出来后,基于Vite生态下的静态网页生成器，是一个非常棒的组件，速度飞快，当这次我并没有选择这个。原因后面会说明&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://hexo.io/zh-cn/&quot;&gt;Hexo&lt;/a&gt; :快速、简洁且高效的博客框架,也是很早的一个框架，主题样式非常的多，&lt;a href=&quot;https://www.luxiangdong.com/&quot;&gt;员外的网站&lt;/a&gt;就使用了这个框架&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://docusaurus.io/&quot;&gt;Docusaurus&lt;/a&gt;: 基于React技术栈的一个静态网站生成器，同样非常的优秀，目前&lt;a href=&quot;https://doc.xiaominfo.com/&quot;&gt;Knife4j&lt;/a&gt;的开源技术文档用这个编写&lt;/li&gt;
  &lt;li&gt;👉 &lt;a href=&quot;https://jekyllrb.com/&quot;&gt;Jekyll&lt;/a&gt; : 基于Ruby语言编写的老牌博客框架，本期的主角&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;这里选择&lt;a href=&quot;https://jekyllrb.com/&quot;&gt;Jekyll&lt;/a&gt; 主要原因有几个：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;之前的博客就是用&lt;a href=&quot;https://jekyllrb.com/&quot;&gt;Jekyll&lt;/a&gt; 来写的，而迁移博客是一项比较繁杂的任务，不想浪费太多的时间&lt;/li&gt;
  &lt;li&gt;博客网站我觉得&lt;strong&gt;最重要的是在于作者的坚持输出&lt;/strong&gt;，主题只要功能满足要求即可，不必追求太花哨的功能&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;2首页内容&quot;&gt;2.首页内容&lt;/h2&gt;

&lt;p&gt;第二个方面考虑的因素是首页的内容，像&lt;a href=&quot;https://vuepress.vuejs.org/zh/guide/&quot;&gt;VuePress&lt;/a&gt;和&lt;a href=&quot;https://vitepress.dev/&quot;&gt;VitePress&lt;/a&gt;默认的首页内容其实是非常简洁的，我觉得更适合产品的展示，不适合博客，当然你也可以花时间改造，或者选择一个很棒的主题进行替换，这里主要是时间不够，就没有选择这个，并非所他们不好。而我所考虑的是：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;首页的内容要主题鲜明，详细阐述整个站点内容&lt;/li&gt;
  &lt;li&gt;多篇文章则分页，博客必须全部在首页展示，不跳转到二级页面&lt;/li&gt;
  &lt;li&gt;尽可能多的展示内容，&lt;strong&gt;首页的资源是非常宝贵的&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;以下就是该博客的首页，非常符合我的诉求&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/blog2/jekyll-theme-share/blog_index.png&quot; alt=&quot;图2-博客首页&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;3基本功能&quot;&gt;3.基本功能&lt;/h2&gt;

&lt;p&gt;接下来就是考虑博客框架一个基础的功能，这里从个人的诉求，列了以下的要求：&lt;/p&gt;

&lt;h3 id=&quot;31-适配移动端&quot;&gt;3.1 &lt;strong&gt;适配移动端&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;移动端时代，这是一个非常重要的特性&lt;/strong&gt;，有时候在发公众号文章时可以在底部配置原文链接，对于读者来说可以无差别阅读&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/blog2/jekyll-theme-share/blog_mobile.png&quot; alt=&quot;图3-移动端适配&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;32-站内搜索&quot;&gt;3.2 &lt;strong&gt;站内搜索&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;可以提供站内搜索的功能，不管是构建本地博客索引还是使用外部的实现，例如《&lt;a href=&quot;/posts/knife4j-document-active-search/&quot;&gt;Final.激活Knife4j官网的文档搜索功能&lt;/a&gt;》提到的&lt;a href=&quot;https://www.algolia.com/&quot;&gt;algolia&lt;/a&gt;都是可以的&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/blog2/jekyll-theme-share/blog_search.png&quot; alt=&quot;图4-站内搜索&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;33-归档功能&quot;&gt;3.3 &lt;strong&gt;归档功能&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;不管是分类还是日期归档，都是必须的功能&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;分类归档：能够给读者一个快速索引，查看感兴趣的内容&lt;/li&gt;
  &lt;li&gt;日期归档: 根据最新日期查看更新的篇幅,同时也是对作者的一个鞭策，非常实用&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/images/blog2/jekyll-theme-share/blog_arch.png&quot; alt=&quot;图5-归档&quot; /&gt;
&lt;img src=&quot;/images/blog2/jekyll-theme-share/blog_arch1.png&quot; alt=&quot;图6-归档1&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;34-评论功能&quot;&gt;3.4 &lt;strong&gt;评论功能&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;评论算是一个个人诉求吧,并非强制，当然如果有默认提供那更好，本站点基于&lt;a href=&quot;https://giscus.app/zh-CN&quot;&gt;giscus&lt;/a&gt;实现
&lt;img src=&quot;/images/blog2/jekyll-theme-share/blog_comment.png&quot; alt=&quot;图7-评论&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;35-文章分享&quot;&gt;3.5 &lt;strong&gt;文章分享&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;快速分享到各大社交平台，非常实用的功能&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/blog2/jekyll-theme-share/blog_share.jpg&quot; alt=&quot;图7-分享&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;36-站点统计&quot;&gt;3.6 &lt;strong&gt;站点统计&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;该功能我想目前各个框架都支持，使用百度统计或者Google Analytics应该都非常方便&lt;/p&gt;

&lt;h3 id=&quot;37-rss&quot;&gt;3.7 &lt;strong&gt;RSS&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;根据个人喜好提供&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/blog2/jekyll-theme-share/blog_feed.jpg&quot; alt=&quot;图8-评论&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;4-博客大纲&quot;&gt;4. 博客大纲&lt;/h2&gt;

&lt;p&gt;个人的博客，我觉得整体的大纲内容不必太多，只需要关注写作内容即可，能够将写作内容能够快速的索引到并且给读者一个清晰的结构，就可以了&lt;/p&gt;

&lt;p&gt;所以我的博客大纲主要是四个： &lt;strong&gt;主页&lt;/strong&gt;、&lt;strong&gt;标签&lt;/strong&gt;、&lt;strong&gt;归档&lt;/strong&gt;、&lt;strong&gt;关于&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;5总结&quot;&gt;5.总结&lt;/h2&gt;

&lt;p&gt;本站的博客基于&lt;a href=&quot;https://jekyllrb.com/&quot;&gt;Jekyll&lt;/a&gt;的&lt;a href=&quot;https://github.com/cotes2020/jekyll-theme-chirpy&quot;&gt;chirpy&lt;/a&gt;主题实现，该主题满足了博主的所有诉求，非常棒，希望你也能够喜欢!!!&lt;/p&gt;

&lt;p&gt;本站源码：&lt;a href=&quot;https://github.com/xiaoymin/xiaoymin.github.io&quot;&gt;https://github.com/xiaoymin/xiaoymin.github.io&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;博客首页：&lt;a href=&quot;https://www.xiaominfo.com/&quot;&gt;https://www.xiaominfo.com/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;主题地址: &lt;a href=&quot;https://github.com/cotes2020/jekyll-theme-chirpy&quot;&gt;https://github.com/cotes2020/jekyll-theme-chirpy&lt;/a&gt;&lt;/p&gt;</content><author><name>八一菜刀</name></author><category term="Blog" /><summary type="html">最近在学习RAG、大模型等领域方面的技术，想在学习的过程中做总结性的输出，因此就想把自己之前弄的博客重新整理一番,主要有几个原因:</summary></entry></feed>